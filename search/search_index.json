{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Polars-Bloomberg","text":""},{"location":"#polars-bloomberg-open-api","title":"Polars + Bloomberg Open API","text":"<p>polars-bloomberg is a Python library that extracts Bloomberg\u2019s financial data directly into Polars DataFrames.  If you\u2019re a quant financial analyst, data scientist, or quant developer working in capital markets, this library makes it easy to fetch, transform, and analyze Bloomberg data right in Polars\u2014offering speed, efficient memory usage, and a lot of fun to use!</p>"},{"location":"#installation-requirements","title":"Installation &amp; Requirements","text":"<ul> <li>Bloomberg Access: A valid Bloomberg terminal license is required!</li> <li>Bloomberg Python API: The <code>blpapi</code> library must be installed. See the Bloomberg API Library.</li> <li>Python Version: Python 3.12+ recommended.</li> </ul> <pre><code>pip install polars-bloomberg\n</code></pre>"},{"location":"#quick-start","title":"Quick Start","text":"<p>\"Hello World\" Example (under 1 minute): <pre><code>from polars_bloomberg import BQuery\n\n# Fetch the latest price for Apple (AAPL US Equity)\nwith BQuery() as bq:\n    df = bq.bdp([\"AAPL US Equity\"], [\"PX_LAST\"])\n    print(df)\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 security       \u2506 PX_LAST \u2502\n\u2502 ---            \u2506 ---     \u2502\n\u2502 str            \u2506 f64     \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 AAPL US Equity \u2506 248.13  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> What this does: - Establishes a Bloomberg connection using the context manager. - Retrieves the last price of Apple shares. - Returns the result as a Polars DataFrame.</p> <p>If you see a price in <code>df</code>, your setup is working \ud83e\udd29!!!</p>"},{"location":"#cheat-sheet","title":"Cheat Sheet","text":"Method Description <code>bdp()</code> Fetch single-value fields (e.g., last price). more..  <code>bdh()</code> Retrieve historical data (e.g., time series). more..  <code>bdib()</code> Download intraday bar data at minute resolution. more..  <code>bsrch()</code> Excel-style search grids (SRCH/BI/COMDTY domains). more..  <code>bql()</code> Execute complex Bloomberg Query Language requests. more.."},{"location":"api/","title":"API Reference","text":""},{"location":"api/#polars_bloomberg.BQuery","title":"<code>polars_bloomberg.BQuery</code>","text":"<p>Provides methods to query Bloomberg API and return data as Polars DataFrames.</p> Example <p>Create a BQuery instance and fetch last price for Apple stock:</p> <pre><code>from polars_bloomberg import BQuery\n\nwith BQuery() as bq:\n    df = bq.bdp(['AAPL US Equity'], ['PX_LAST'])\nprint(df)\n</code></pre> <p>Expected output: <pre><code>shape: (1, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 security       \u2506 PX_LAST  \u2502\n\u2502 ---            \u2506 ---      \u2502\n\u2502 str            \u2506 f64      \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 AAPL US Equity \u2506 171.32   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> Source code in <code>polars_bloomberg\\plbbg.py</code> <pre><code>class BQuery:\n    \"\"\"Provides methods to query Bloomberg API and return data as Polars DataFrames.\n\n    Example:\n        Create a BQuery instance and fetch last price for Apple stock:\n\n        ```python\n        from polars_bloomberg import BQuery\n\n        with BQuery() as bq:\n            df = bq.bdp(['AAPL US Equity'], ['PX_LAST'])\n        print(df)\n        ```\n\n        Expected output:\n        ```python\n        shape: (1, 2)\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502 security       \u2506 PX_LAST  \u2502\n        \u2502 ---            \u2506 ---      \u2502\n        \u2502 str            \u2506 f64      \u2502\n        \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        \u2502 AAPL US Equity \u2506 171.32   \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        ```\n\n    \"\"\"\n\n    session: blpapi.Session\n\n    def __init__(\n        self,\n        host: str = \"localhost\",\n        port: int = 8194,\n        timeout: int = 32_000,\n        debug: bool = False,\n    ) -&gt; None:\n        \"\"\"Initialize a BQuery instance with connection parameters.\n\n        Args:\n            host (str, optional):\n                The hostname for the Bloomberg API server.\n                Defaults to \"localhost\".\n            port (int, optional):\n                The port number for the Bloomberg API server.\n                Defaults to 8194.\n            timeout (int, optional):\n                Timeout in milliseconds for API requests.\n                Defaults to 32000.\n            debug (bool, optional):\n                Enable debug logging/saving of intermediate results.\n                Defaults to False.\n\n        Raises:\n            ConnectionError: If unable to establish connection to Bloomberg API.\n\n        \"\"\"\n        self.host = host\n        self.port = port\n        self.timeout = timeout\n        self.debug = debug\n\n    def __enter__(self):  # noqa: D105\n        # Enter the runtime context related to this object.\n        options = blpapi.SessionOptions()\n        options.setServerHost(self.host)\n        options.setServerPort(self.port)\n        self.session = blpapi.Session(options)\n\n        if not self.session.start():\n            raise ConnectionError(\"Failed to start Bloomberg session.\")\n\n        # Open both required services\n        if not self.session.openService(\"//blp/refdata\"):\n            raise ConnectionError(\"Failed to open service //blp/refdata.\")\n        if not self.session.openService(\"//blp/bqlsvc\"):\n            raise ConnectionError(\"Failed to open service //blp/bqlsvc.\")\n        if not self.session.openService(\"//blp/exrsvc\"):\n            raise ConnectionError(\"Failed to open service //blp/exrsvc.\")\n\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):  # noqa: D105\n        # Exit the context manager and stop the Bloomberg session.\n        if self.session:\n            self.session.stop()\n\n    def bdp(\n        self,\n        securities: list[str],\n        fields: list[str],\n        overrides: list[tuple] | None = None,\n        options: dict | None = None,\n    ) -&gt; pl.DataFrame:\n        \"\"\"Bloomberg Data Point, equivalent to Excel BDP() function.\n\n        Fetch reference data for given securities and fields.\n\n        Args:\n            securities (list[str]): List of security identifiers (e.g. 'AAPL US Equity').\n            fields (list[str]): List of data fields to retrieve (e.g., 'PX_LAST').\n            overrides (list[tuple], optional): List of tuples for field overrides. Defaults to None.\n            options (dict, optional): Additional request options. Defaults to None.\n\n        Returns:\n            pl.DataFrame: A Polars DataFrame containing the requested reference data.\n\n        Raises:\n            ConnectionError: If there is an issue with the Bloomberg session.\n            ValueError: If the request parameters are invalid.\n\n        Example:\n            Fetch last price for Apple and Microsoft stocks:\n\n            ```python\n            from polars_bloomberg import BQuery\n\n            with BQuery() as bq:\n                df = bq.bdp(['AAPL US Equity', 'MSFT US Equity'], ['PX_LAST'])\n            print(df)\n            ```\n\n            Expected output:\n            ```python\n            shape: (2, 2)\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u2502 security       \u2506 PX_LAST  \u2502\n            \u2502 ---            \u2506 ---      \u2502\n            \u2502 str            \u2506 f64      \u2502\n            \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n            \u2502 AAPL US Equity \u2506 171.32   \u2502\n            \u2502 MSFT US Equity \u2506 232.33   \u2502\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            ```\n\n        \"\"\"  # noqa: E501\n        request = self._create_request(\n            \"ReferenceDataRequest\", securities, fields, overrides, options\n        )\n        responses = self._send_request(request)\n        data = self._parse_bdp_responses(responses, fields)\n        return pl.DataFrame(data)\n\n    def bdh(\n        self,\n        securities: list[str],\n        fields: list[str],\n        start_date: date,\n        end_date: date,\n        overrides: list[tuple] | None = None,\n        options: dict | None = None,\n    ) -&gt; pl.DataFrame:\n        \"\"\"Bloomberg Data History, equivalent to Excel BDH() function.\n\n        Fetch historical data for given securities and fields between dates.\n\n        Args:\n            securities (list[str]): List of security identifiers (e.g., 'AAPL US Equity').\n            fields (list[str]): List of data fields to retrieve (e.g., 'PX_LAST').\n            start_date (date): Start date for the historical data.\n            end_date (date): End date for the historical data.\n            overrides (list[tuple], optional): List of tuples for field overrides. Defaults to None.\n            options (dict, optional): Additional request options. Defaults to None.\n\n        Returns:\n            pl.DataFrame: A Polars DataFrame containing the requested historical data.\n\n        Raises:\n            ConnectionError: If there is an issue with the Bloomberg session.\n            ValueError: If the request parameters are invalid.\n\n        Example:\n            Fetch historical closing prices for TLT:\n\n            ```python\n            from datetime import date\n            from polars_bloomberg import BQuery\n\n            with BQuery() as bq:\n                df = bq.bdh(\n                    [\"TLT US Equity\"],\n                    [\"PX_LAST\"],\n                    start_date=date(2019, 1, 1),\n                    end_date=date(2019, 1, 7),\n                )\n            print(df)\n            ```\n\n            Expected output:\n            ```python\n            shape: (4, 3)\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u2502 security      \u2506 date       \u2506 PX_LAST \u2502\n            \u2502 ---           \u2506 ---        \u2506 ---     \u2502\n            \u2502 str           \u2506 date       \u2506 f64     \u2502\n            \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n            \u2502 TLT US Equity \u2506 2019-01-02 \u2506 122.15  \u2502\n            \u2502 TLT US Equity \u2506 2019-01-03 \u2506 123.54  \u2502\n            \u2502 TLT US Equity \u2506 2019-01-04 \u2506 122.11  \u2502\n            \u2502 TLT US Equity \u2506 2019-01-07 \u2506 121.75  \u2502\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            ```\n\n        \"\"\"  # noqa: E501\n        request = self._create_request(\n            \"HistoricalDataRequest\", securities, fields, overrides, options\n        )\n        request.set(\"startDate\", start_date.strftime(\"%Y%m%d\"))\n        request.set(\"endDate\", end_date.strftime(\"%Y%m%d\"))\n        responses = self._send_request(request)\n        data = self._parse_bdh_responses(responses, fields)\n        return pl.DataFrame(data, infer_schema_length=None)\n\n    def bdib(  # noqa: PLR0913\n        self,\n        security: str,\n        event_type: str,\n        interval: int,\n        start_datetime: datetime,\n        end_datetime: datetime,\n        overrides: Sequence | None = None,\n        options: dict | None = None,\n    ) -&gt; pl.DataFrame:\n        \"\"\"Fetch intraday bars from Bloomberg, mirroring Excel's BDIB() function.\n\n        Args:\n            security (str): Instrument identifier (for example 'AAPL US Equity').\n            event_type (str): One of TRADE, BID, ASK, BEST_BID, BEST_ASK.\n            interval (int): Bar length in minutes (1-1440).\n            start_datetime (datetime): First bar timestamp; naive vals are treated as UTC\n                tz-aware values are converted to UTC before the request is sent.\n            end_datetime (datetime): Last bar timestamp; handled same way as start_dtm\n            overrides (Sequence | None, optional): Sequence of (field, value) overrides.\n            options (dict | None, optional): Additional Bloomberg request options.\n\n        Returns:\n            pl.DataFrame: Bars sorted by security/time with columns\n                ['security', 'time', 'open', 'high', 'low', 'close', 'volume',\n                'numEvents', 'value']. Bloomberg emits `time` in UTC and the DataFrame\n                preserves that timezone.\n\n        Example:\n            ```python\n            from datetime import datetime\n            from polars_bloomberg import BQuery\n\n            with BQuery() as bq:\n                df = bq.bdib(\n                    \"OMX Index\",\n                    event_type=\"TRADE\",\n                    interval=60,\n                    start_datetime=datetime(2025, 11, 5),\n                    end_datetime=datetime(2025, 11, 6),\n                )\n                print(df)\n            ```\n\n             Expected output:\n            ```python\n            shape: (4, 3)\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u2502 security  \u2506 time         \u2506 open     \u2506 high     \u2506 \u2026 \u2506 close    \u2506 volume \u2506 numEvents \u2506 value \u2502\n            \u2502 ---       \u2506 ---          \u2506 ---      \u2506 ---      \u2506   \u2506 ---      \u2506 ---    \u2506 ---       \u2506 ---   \u2502\n            \u2502 str       \u2506 datetime[\u03bcs] \u2506 f64      \u2506 f64      \u2506   \u2506 f64      \u2506 i64    \u2506 i64       \u2506 f64   \u2502\n            \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n            \u2502 OMX Index \u2506 2025-11-05   \u2506 2726.603 \u2506 2742.014 \u2506 \u2026 \u2506 2739.321 \u2506 0      \u2506 3591      \u2506 0.0   \u2502\n            \u2502           \u2506 08:00:00     \u2506          \u2506          \u2506   \u2506          \u2506        \u2506           \u2506       \u2502\n            \u2502 OMX Index \u2506 2025-11-05   \u2506 2739.466 \u2506 2739.706 \u2506 \u2026 \u2506 2733.836 \u2506 0      \u2506 3600      \u2506 0.0   \u2502\n            \u2502           \u2506 09:00:00     \u2506          \u2506          \u2506   \u2506          \u2506        \u2506           \u2506       \u2502\n            \u2502 OMX Index \u2506 2025-11-05   \u2506 2733.747 \u2506 2734.827 \u2506 \u2026 \u2506 2731.724 \u2506 0      \u2506 3600      \u2506 0.0   \u2502\n            \u2502           \u2506 10:00:00     \u2506          \u2506          \u2506   \u2506          \u2506        \u2506           \u2506       \u2502\n            \u2502 OMX Index \u2506 2025-11-05   \u2506 2731.721 \u2506 2742.015 \u2506 \u2026 \u2506 2741.185 \u2506 0      \u2506 3600      \u2506 0.0   \u2502\n            \u2502           \u2506 11:00:00     \u2506          \u2506          \u2506   \u2506          \u2506        \u2506           \u2506       \u2502\n            \u2502 OMX Index \u2506 2025-11-05   \u2506 2741.256 \u2506 2747.291 \u2506 \u2026 \u2506 2747.291 \u2506 0      \u2506 3600      \u2506 0.0   \u2502\n            \u2502           \u2506 12:00:00     \u2506          \u2506          \u2506   \u2506          \u2506        \u2506           \u2506       \u2502\n            \u2502 OMX Index \u2506 2025-11-05   \u2506 2747.291 \u2506 2748.815 \u2506 \u2026 \u2506 2748.287 \u2506 0      \u2506 3600      \u2506 0.0   \u2502\n            \u2502           \u2506 13:00:00     \u2506          \u2506          \u2506   \u2506          \u2506        \u2506           \u2506       \u2502\n            \u2502 OMX Index \u2506 2025-11-05   \u2506 2748.273 \u2506 2752.301 \u2506 \u2026 \u2506 2752.181 \u2506 0      \u2506 3600      \u2506 0.0   \u2502\n            \u2502           \u2506 14:00:00     \u2506          \u2506          \u2506   \u2506          \u2506        \u2506           \u2506       \u2502\n            \u2502 OMX Index \u2506 2025-11-05   \u2506 2752.181 \u2506 2758.978 \u2506 \u2026 \u2506 2752.495 \u2506 0      \u2506 3600      \u2506 0.0   \u2502\n            \u2502           \u2506 15:00:00     \u2506          \u2506          \u2506   \u2506          \u2506        \u2506           \u2506       \u2502\n            \u2502 OMX Index \u2506 2025-11-05   \u2506 2752.402 \u2506 2752.85  \u2506 \u2026 \u2506 2751.404 \u2506 0      \u2506 2100      \u2506 0.0   \u2502\n            \u2502           \u2506 16:00:00     \u2506          \u2506          \u2506   \u2506          \u2506        \u2506           \u2506       \u2502\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            ```\n\n        \"\"\"  # noqa: E501\n        request = self._create_intraday_bar_request(\n            security=security,\n            event_type=event_type,\n            interval=interval,\n            start_datetime=start_datetime,\n            end_datetime=end_datetime,\n            overrides=overrides,\n            options=options,\n        )\n        responses = self._send_request(request)\n        data = self._parse_bdib_responses(responses, fallback_security=security)\n        schema = {\n            \"security\": pl.Utf8,\n            \"time\": pl.Datetime,\n            \"open\": pl.Float64,\n            \"high\": pl.Float64,\n            \"low\": pl.Float64,\n            \"close\": pl.Float64,\n            \"volume\": pl.Int64,\n            \"numEvents\": pl.Int64,\n            \"value\": pl.Float64,\n        }\n        df = pl.DataFrame(data, schema=schema, strict=False, infer_schema_length=None)\n        return df.sort([\"security\", \"time\"]) if not df.is_empty() else df\n\n    def bql(self, expression: str) -&gt; BqlResult:\n        \"\"\"Execute a Bloomberg Query Language (BQL) query.\n\n        BQL is Bloomberg's domain-specific language for complex financial queries. It allows\n        for advanced data retrieval, screening, and analysis.\n\n        Args:\n            expression (str): The BQL query expression to execute. Can include functions like\n                get(), let(), for(), filter(), etc.\n\n        Returns:\n            BqlResult: An object containing:\n                - List of Polars DataFrames (one for each item in BQL get statement)\n                - Helper methods like combine() to merge DataFrames on common columns\n                Returns empty result if BQL syntax is invalid (error is logged).\n\n        Raises:\n            ConnectionError: If there is an issue with the Bloomberg session.\n\n        Example:\n            Simple query to fetch last price:\n\n            ```python\n            from polars_bloomberg import BQuery\n\n            with BQuery() as bq:\n                # Get last price for multiple securities\n                result = bq.bql(\"get(px_last) for(['IBM US Equity', 'MSFT US Equity'])\")\n                df = result.combine()\n                print(df)\n            ```\n\n            Expected output:\n            ```python\n            shape: (2, 4)\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u2502 ID            \u2506 PX_LAST \u2502\n            \u2502 ---           \u2506 ---     \u2502\n            \u2502 str           \u2506 f64     \u2502\n            \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n            \u2502 AAPL US Equity\u2506 150.25  \u2502\n            \u2502 MSFT US Equity\u2506 250.80  \u2502\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            ```\n\n            Access individual DataFrames:\n            ```python\n            &gt;&gt;&gt; df_px_last = result[0]\n            &gt;&gt;&gt; print(df_px_last)\n            shape: (2, 2)\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u2502 ID            \u2506 PX_LAST \u2502\n            \u2502 ---           \u2506 ---     \u2502\n            \u2502 str           \u2506 f64     \u2502\n            \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n            \u2502 AAPL US Equity\u2506 150.25  \u2502\n            \u2502 MSFT US Equity\u2506 250.80  \u2502\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            ```\n            Fetch multiple fields and combine results:\n            ```python\n            &gt;&gt;&gt; result = bq.bql(\"get(px_last, px_volume) for('AAPL US Equity')\")\n            &gt;&gt;&gt; df_combined = result.combine()\n            &gt;&gt;&gt; print(df_combined)\n            shape: (1, 3)\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u2502 ID            \u2506 PX_LAST \u2506 PX_VOLUME  \u2502\n            \u2502 ---           \u2506 ---     \u2506 ---        \u2502\n            \u2502 str           \u2506 f64     \u2506 f64        \u2502\n            \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n            \u2502 AAPL US Equity\u2506 150.25  \u2506 30000000.0 \u2502\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            ```\n            Iterate over individual DataFrames:\n            ```python\n            &gt;&gt;&gt; for df in result:\n            ...     print(df)\n            ```\n\n        \"\"\"  # noqa: E501\n        request = self._create_bql_request(expression)\n        responses = self._send_request(request)\n        tables = self._parse_bql_responses(responses)\n        dataframes = [\n            pl.DataFrame(table.data, schema=table.schema, strict=True)\n            for table in tables\n        ]\n        names = [table.name for table in tables]\n        return BqlResult(dataframes, names)\n\n    def bsrch(\n        self,\n        domain: str,\n        overrides: dict[str, Any] | None = None,\n        options: dict | None = None,\n    ) -&gt; pl.DataFrame:\n        r\"\"\"Bloomberg SRCH (search) via ExcelGetGridRequest on //blp/exrsvc.\n\n        Args:\n            domain: Domain string, e.g. ``\\\"FI:SRCHEX.@COCO\\\"``.\n            overrides: Optional override map (e.g. ``{\\\"LIMIT\\\": 20000}``).\n            options: Additional request options applied directly to the request.\n\n        Returns:\n            pl.DataFrame with one row per search record and columns from the grid.\n\n        Raises:\n            ValueError: When Bloomberg returns an error string in GridResponse.\n            TimeoutError/ConnectionError: As surfaced by the session helpers.\n\n        Example:\n            Fetch Contingent COnvertible bonds based on Example Search @COCO\n            For sake of example limit number of bonds to two\n\n            ```python\n            from polars_bloomberg import BQuery\n\n            with BQuery() as bq:\n                df = bq.bsrch(\"FI:SRCHEX.@COCO\", {\"LIMIT\": 2})\n                print(df)\n            ```\n\n            Expected output:\n            ```python\n            BSRCH response reached internal limit; consider using LIMIT override.\n            shape: (2, 1)\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u2502 id            \u2502\n            \u2502 ---           \u2502\n            \u2502 str           \u2502\n            \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n            \u2502 DA785784 Corp \u2502\n            \u2502 DA773901 Corp \u2502\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            ```\n\n        \"\"\"\n        request = self._create_bsrch_request(domain, overrides, options)\n        responses = self._send_request(request)\n        limit_applied = bool(overrides and \"LIMIT\" in overrides)\n        rows = self._parse_bsrch_responses(responses, limit_applied=limit_applied)\n        return pl.DataFrame(rows, infer_schema_length=None, strict=False)\n\n    def _create_request(\n        self,\n        request_type: str,\n        securities: list[str],\n        fields: list[str],\n        overrides: Sequence | None = None,\n        options: dict | None = None,\n    ) -&gt; blpapi.Request:\n        \"\"\"Create a Bloomberg request with support for overrides and options.\"\"\"\n        service = self.session.getService(\"//blp/refdata\")\n        request = service.createRequest(request_type)\n\n        # Add securities\n        securities_element = request.getElement(\"securities\")\n        for security in securities:\n            securities_element.appendValue(security)\n\n        # Add fields\n        fields_element = request.getElement(\"fields\")\n        for field in fields:\n            fields_element.appendValue(field)\n\n        # Add overrides if provided\n        if overrides:\n            overrides_element = request.getElement(\"overrides\")\n            for field_id, value in overrides:\n                override_element = overrides_element.appendElement()\n                override_element.setElement(\"fieldId\", field_id)\n                override_element.setElement(\"value\", value)\n\n        # Add additional options if provided\n        if options:\n            for key, value in options.items():\n                request.set(key, value)\n\n        return request\n\n    def _create_bsrch_request(\n        self,\n        domain: str,\n        overrides: dict[str, Any] | None = None,\n        options: dict | None = None,\n    ) -&gt; blpapi.Request:\n        \"\"\"Create an ExcelGetGridRequest for BSRCH on //blp/exrsvc.\"\"\"\n        service = self.session.getService(\"//blp/exrsvc\")\n        request = service.createRequest(\"ExcelGetGridRequest\")\n        request.set(\"Domain\", domain)\n\n        if overrides:\n            overrides_element = request.getElement(\"Overrides\")\n            for name, value in overrides.items():\n                override = overrides_element.appendElement()\n                override.setElement(\"name\", str(name))\n                override.setElement(\"value\", str(value))\n\n        if options:\n            for key, value in options.items():\n                request.set(key, value)\n\n        return request\n\n    def _create_intraday_bar_request(  # noqa: PLR0913\n        self,\n        security: str,\n        event_type: str,\n        interval: int,\n        start_datetime: datetime,\n        end_datetime: datetime,\n        overrides: Sequence | None,\n        options: dict | None,\n    ) -&gt; blpapi.Request:\n        \"\"\"Create an IntradayBarRequest with overrides and options support.\"\"\"\n        service = self.session.getService(\"//blp/refdata\")\n        request = service.createRequest(\"IntradayBarRequest\")\n        request.set(\"security\", security)\n        request.set(\"eventType\", event_type)\n        request.set(\"interval\", interval)\n        request.set(\"startDateTime\", self._format_datetime(start_datetime))\n        request.set(\"endDateTime\", self._format_datetime(end_datetime))\n\n        if overrides:\n            overrides_element = request.getElement(\"overrides\")\n            for field_id, value in overrides:\n                override_element = overrides_element.appendElement()\n                override_element.setElement(\"fieldId\", field_id)\n                override_element.setElement(\"value\", value)\n\n        if options:\n            for key, value in options.items():\n                request.set(key, value)\n\n        return request\n\n    def _create_bql_request(self, expression: str) -&gt; blpapi.Request:\n        \"\"\"Create a BQL request.\"\"\"\n        service = self.session.getService(\"//blp/bqlsvc\")\n        request = service.createRequest(\"sendQuery\")\n        request.set(\"expression\", expression)\n        # BLPAPI requires setting sub-elements on the sequence element.\n        try:\n            ctx = request.getElement(\"clientContext\")\n            ctx.setElement(\"appName\", \"EXCEL\")\n        except blpapi.NotFoundException:\n            logger.debug(\n                \"BQL request has no 'clientContext' element in this SDK/schema.\"\n            )\n\n        return request\n\n    def _send_request(self, request) -&gt; list[dict]:\n        \"\"\"Send a Bloomberg request and collect responses with timeout handling.\"\"\"\n        self.session.sendRequest(request)\n        responses = []\n        while True:\n            # Wait for an event with the specified timeout\n            event = self.session.nextEvent(self.timeout)\n            if event.eventType() == blpapi.Event.TIMEOUT:\n                # Handle the timeout scenario\n                raise TimeoutError(\n                    f\"Request timed out after {self.timeout} milliseconds\"\n                )\n            for msg in event:\n                # Check for errors in the message\n                if msg.hasElement(\"responseError\"):\n                    error = msg.getElement(\"responseError\")\n                    error_message = error.getElementAsString(\"message\")\n                    raise Exception(f\"Response error: {error_message}\")\n                responses.append(msg.toPy())\n            # Break the loop when the final response is received\n            if event.eventType() == blpapi.Event.RESPONSE:\n                break\n\n        if getattr(self, \"debug\", False):\n            os.makedirs(\"debug_cases\", exist_ok=True)\n            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\")\n            with open(\n                f\"debug_cases/responses_{timestamp}.json\", \"w\", encoding=\"utf-8\"\n            ) as f:\n                json.dump(responses, f, default=str, indent=2)\n        return responses\n\n    def _parse_bdp_responses(\n        self, responses: list[dict], fields: list[str]\n    ) -&gt; list[dict]:\n        data = []\n        for response in responses:\n            security_data = response.get(\"securityData\", [])\n            for sec in security_data:\n                security = sec.get(\"security\")\n                field_data = sec.get(\"fieldData\", {})\n                record = {\"security\": security}\n                for field in fields:\n                    record[field] = field_data.get(field)\n                data.append(record)\n        return data\n\n    def _parse_bdh_responses(\n        self, responses: list[dict], fields: list[str]\n    ) -&gt; list[dict]:\n        data = []\n        for response in responses:\n            security_data = response.get(\"securityData\", {})\n            security = security_data.get(\"security\")\n            field_data_array = security_data.get(\"fieldData\", [])\n            for entry in field_data_array:\n                record = {\"security\": security, \"date\": entry.get(\"date\")}\n                for field in fields:\n                    record[field] = entry.get(field)\n                data.append(record)\n        return data\n\n    def _parse_bdib_responses(\n        self, responses: list[dict], fallback_security: str | None = None\n    ) -&gt; list[dict]:\n        bars: list[dict[str, Any]] = []\n        for response in responses:\n            bar_data = response.get(\"barData\", {})\n            security = bar_data.get(\"security\") or fallback_security\n            entries = bar_data.get(\"barTickData\", [])\n            for entry in entries:\n                bar_entry = entry.get(\"barTickData\", entry)\n                record = {\n                    \"security\": security,\n                    \"time\": bar_entry.get(\"time\"),\n                    \"open\": bar_entry.get(\"open\"),\n                    \"high\": bar_entry.get(\"high\"),\n                    \"low\": bar_entry.get(\"low\"),\n                    \"close\": bar_entry.get(\"close\"),\n                    \"volume\": bar_entry.get(\"volume\"),\n                    \"numEvents\": bar_entry.get(\"numEvents\"),\n                    \"value\": bar_entry.get(\"value\"),\n                }\n                bars.append(record)\n        return bars\n\n    def _parse_bsrch_responses(\n        self, responses: list[dict], *, limit_applied: bool = False\n    ) -&gt; list[dict]:\n        \"\"\"Parse GridResponse payloads from ExcelGetGridRequest.\"\"\"\n        rows: list[dict[str, Any]] = []\n        errors: list[str] = []\n        reach_max = False\n        column_titles: list[str] | None = None\n\n        for response in responses:\n            grid = response.get(\"GridResponse\", {})\n            if not grid and any(\n                key in response for key in (\"NumOfFields\", \"NumOfRecords\", \"DataRecords\")\n            ):\n                grid = response\n            if not grid:\n                continue\n\n            column_titles = grid.get(\"ColumnTitles\") or column_titles\n            reach_max = reach_max or bool(grid.get(\"ReachMax\"))\n            data_records = grid.get(\"DataRecords\", []) or []\n            error_text = grid.get(\"Error\")\n            if error_text and not data_records:\n                errors.append(error_text)\n                continue\n\n            for record in data_records:\n                data_fields = record.get(\"DataFields\", []) or []\n                row: dict[str, Any] = {}\n                for idx, field in enumerate(data_fields):\n                    value = self._extract_bsrch_field_value(field)\n                    col_name = (\n                        column_titles[idx]\n                        if column_titles and idx &lt; len(column_titles)\n                        else f\"col_{idx}\"\n                    )\n                    row[col_name] = value\n                rows.append(row)\n\n        if errors and not rows:\n            raise ValueError(f\"BSRCH error: {errors[0]}\")\n\n        if reach_max and not limit_applied:\n            logger.warning(\n                \"BSRCH response reached internal limit; consider using LIMIT override.\"\n            )\n\n        if rows:\n            self._coerce_bsrch_numeric_columns(rows)\n\n        return rows\n\n    @staticmethod\n    def _extract_bsrch_field_value(field: Any) -&gt; Any:  # noqa: PLR0911\n        \"\"\"Extract typed value from a GridResponse DataField.\"\"\"\n        if not isinstance(field, dict):\n            return field\n\n        # Possible keys observed in GridResponse DataFields\n        key_order = [\n            \"Ticker\",\n            \"StringValue\",\n            \"StringData\",\n            \"value\",\n            \"Value\",\n            \"DoubleData\",\n            \"DoubleValue\",\n            \"FloatValue\",\n            \"Int32Data\",\n            \"Int32Value\",\n            \"IntValue\",\n            \"LongValue\",\n            \"DateValue\",\n            \"TimeValue\",\n            \"DateTimeValue\",\n        ]\n        for key in key_order:\n            if key in field:\n                val = field.get(key)\n                if key.startswith(\"Double\") or key.startswith(\"Float\"):\n                    try:\n                        return float(val)\n                    except (TypeError, ValueError):\n                        return val\n                if key.startswith(\"Int32\") or key in {\"IntValue\", \"LongValue\"}:\n                    try:\n                        return int(val)\n                    except (TypeError, ValueError):\n                        return val\n                if key in {\"DateValue\", \"TimeValue\", \"DateTimeValue\"}:\n                    return val\n                return val\n        # If no known key found, return the dict itself\n        return field\n\n    @staticmethod\n    def _coerce_bsrch_numeric_columns(rows: list[dict[str, Any]]) -&gt; None:\n        \"\"\"Convert empty/whitespace strings to None to allow numeric inference.\"\"\"\n        if not rows:\n            return\n\n        cols = rows[0].keys()\n        for col in cols:\n            values = [row.get(col) for row in rows]\n            cleaned: list[Any] = []\n            numeric_candidate = True\n\n            for val in values:\n                if isinstance(val, str) and val.strip() == \"\":\n                    cleaned.append(None)\n                    continue\n                cleaned.append(val)\n                if val is None or isinstance(val, (int, float)):\n                    continue\n                numeric_candidate = False\n                # leave column untouched if any non-numeric string present\n                # other than whitespace\n                # Note: do not break early to align cleaned length\n\n            if numeric_candidate:\n                for idx, cleaned_val in enumerate(cleaned):\n                    rows[idx][col] = cleaned_val\n\n    def _parse_bql_responses(self, responses: list[Any]):\n        \"\"\"Parse BQL responses into a list of SITable objects.\"\"\"\n        tables: list[SITable] = []\n        results: list[dict] = self._extract_results(responses)\n\n        for result in results:\n            tables.extend(self._parse_result(result))\n        return [self._apply_schema(table) for table in tables]\n\n    def _apply_schema(self, table: SITable) -&gt; SITable:\n        \"\"\"Convert data based on the schema (e.g., str -&gt; date, 'NaN' -&gt; None).\"\"\"\n        date_format = \"%Y-%m-%dT%H:%M:%SZ\"\n        for col, dtype in table.schema.items():\n            if dtype == pl.Date:\n                table.data[col] = [\n                    (\n                        datetime.strptime(v, date_format).date()\n                        if isinstance(v, str)\n                        else None\n                    )\n                    for v in table.data[col]\n                ]\n            elif dtype in {pl.Float64, pl.Int64}:\n\n                def _convert_number(val: Any):\n                    if isinstance(val, str):\n                        lower_val = val.lower()\n                        if lower_val == \"nan\":\n                            return None\n                        if lower_val in {\"infinity\", \"inf\"}:\n                            return float(\"inf\")\n                        if lower_val in {\"-infinity\", \"-inf\"}:\n                            return float(\"-inf\")\n                    return val\n\n                table.data[col] = [_convert_number(x) for x in table.data[col]]\n        return table\n\n    def _extract_results(self, responses: list[Any]) -&gt; list[dict]:\n        \"\"\"Extract the 'results' section from each response, handling JSON strings.\n\n        Logs an error if responseExceptions are present (e.g., BQL syntax errors).\n\n        \"\"\"\n        extracted = []\n        for response in responses:\n            resp_dict = response\n            if isinstance(response, str):\n                try:\n                    resp_dict = json.loads(response)\n                except json.JSONDecodeError as e:\n                    logger.error(\"Failed to decode JSON: %s. Error: %s\", response, e)\n                    continue\n\n            # Skip non-dict responses (e.g., connection metadata)\n            if not isinstance(resp_dict, dict):\n                continue\n\n            # Check for BQL errors in responseExceptions\n            exceptions = resp_dict.get(\"responseExceptions\")\n            if exceptions:\n                error_messages = [\n                    exc.get(\"message\") or exc.get(\"internalMessage\") or \"Unknown error\"\n                    for exc in exceptions\n                    if isinstance(exc, dict)\n                ]\n                if error_messages:\n                    logger.error(\"BQL error: %s\", \"; \".join(error_messages))\n                    continue\n\n            results = resp_dict.get(\"results\")\n            if results:\n                extracted.append(results)\n        return extracted\n\n    def _parse_result(self, results: dict[str, Any]) -&gt; list[SITable]:\n        \"\"\"Convert a single BQL results dictionary into a list[SITable].\"\"\"\n        tables: list[SITable] = []\n        for field, content in results.items():\n            data = {}\n            schema_str = {}\n\n            data[\"ID\"] = content.get(\"idColumn\", {}).get(\"values\", [])\n            data[field] = content.get(\"valuesColumn\", {}).get(\"values\", [])\n\n            schema_str[\"ID\"] = content.get(\"idColumn\", {}).get(\"type\", \"STRING\")\n            schema_str[field] = content.get(\"valuesColumn\", {}).get(\"type\", \"STRING\")\n\n            # Process secondary columns\n            for sec_col in content.get(\"secondaryColumns\", []):\n                name = sec_col.get(\"name\", \"\")\n                data[name] = sec_col.get(\"values\", [])\n                schema_str[name] = sec_col.get(\"type\", str)\n            schema = self._map_types(schema_str)\n            tables.append(SITable(name=field, data=data, schema=schema))\n\n        # If debug mode is on, save the input and output for reproducibility\n        if self.debug:\n            self._save_debug_case(results, tables)\n\n        return tables\n\n    def _map_types(self, type_map: dict[str, str]) -&gt; dict[str, pl.DataType]:\n        \"\"\"Map string-based types to Polars data types. Default to Utf8.\"\"\"\n        mapping = {\n            \"STRING\": pl.Utf8,\n            \"DOUBLE\": pl.Float64,\n            \"INT\": pl.Int64,\n            \"DATE\": pl.Date,\n            \"BOOLEAN\": pl.Boolean,\n        }\n        return {col: mapping.get(t.upper(), pl.Utf8) for col, t in type_map.items()}\n\n    @staticmethod\n    def _format_datetime(value: datetime | str) -&gt; str:\n        \"\"\"Convert datetime objects to Bloomberg's ISO8601 string format.\"\"\"\n        if isinstance(value, str):\n            return value\n        if value.tzinfo is None:\n            return value.strftime(\"%Y-%m-%dT%H:%M:%S\")\n        return value.astimezone(UTC).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n\n    def _save_debug_case(self, in_results: dict, tables: list[SITable]):\n        \"\"\"Save input and output to a JSON file for debugging and test generation.\"\"\"\n        # Create a directory for debug cases if it doesn't exist\n        os.makedirs(\"debug_cases\", exist_ok=True)\n\n        # Create a unique filename with timestamp\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        filename = f\"debug_cases/bql_parse_results_{timestamp}.json\"\n\n        # Prepare serializable data\n        out_tables = []\n        for t in tables:\n            out_tables.append(\n                {\n                    \"name\": t.name,\n                    \"data\": t.data,\n                    \"schema\": {col: str(dtype) for col, dtype in t.schema.items()},\n                }\n            )\n\n        to_save = {\"in_results\": in_results, \"out_tables\": out_tables}\n\n        with open(filename, \"w\", encoding=\"utf-8\") as f:\n            json.dump(to_save, f, indent=2)\n\n        logger.debug(\"Saved debug case to %s\", filename)\n</code></pre>"},{"location":"api/#polars_bloomberg.BQuery.__init__","title":"<code>__init__(host='localhost', port=8194, timeout=32000, debug=False)</code>","text":"<p>Initialize a BQuery instance with connection parameters.</p> <p>Parameters:</p> Name Type Description Default <code>host</code> <code>str</code> <p>The hostname for the Bloomberg API server. Defaults to \"localhost\".</p> <code>'localhost'</code> <code>port</code> <code>int</code> <p>The port number for the Bloomberg API server. Defaults to 8194.</p> <code>8194</code> <code>timeout</code> <code>int</code> <p>Timeout in milliseconds for API requests. Defaults to 32000.</p> <code>32000</code> <code>debug</code> <code>bool</code> <p>Enable debug logging/saving of intermediate results. Defaults to False.</p> <code>False</code> <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If unable to establish connection to Bloomberg API.</p> Source code in <code>polars_bloomberg\\plbbg.py</code> <pre><code>def __init__(\n    self,\n    host: str = \"localhost\",\n    port: int = 8194,\n    timeout: int = 32_000,\n    debug: bool = False,\n) -&gt; None:\n    \"\"\"Initialize a BQuery instance with connection parameters.\n\n    Args:\n        host (str, optional):\n            The hostname for the Bloomberg API server.\n            Defaults to \"localhost\".\n        port (int, optional):\n            The port number for the Bloomberg API server.\n            Defaults to 8194.\n        timeout (int, optional):\n            Timeout in milliseconds for API requests.\n            Defaults to 32000.\n        debug (bool, optional):\n            Enable debug logging/saving of intermediate results.\n            Defaults to False.\n\n    Raises:\n        ConnectionError: If unable to establish connection to Bloomberg API.\n\n    \"\"\"\n    self.host = host\n    self.port = port\n    self.timeout = timeout\n    self.debug = debug\n</code></pre>"},{"location":"api/#polars_bloomberg.BQuery.bdh","title":"<code>bdh(securities, fields, start_date, end_date, overrides=None, options=None)</code>","text":"<p>Bloomberg Data History, equivalent to Excel BDH() function.</p> <p>Fetch historical data for given securities and fields between dates.</p> <p>Parameters:</p> Name Type Description Default <code>securities</code> <code>list[str]</code> <p>List of security identifiers (e.g., 'AAPL US Equity').</p> required <code>fields</code> <code>list[str]</code> <p>List of data fields to retrieve (e.g., 'PX_LAST').</p> required <code>start_date</code> <code>date</code> <p>Start date for the historical data.</p> required <code>end_date</code> <code>date</code> <p>End date for the historical data.</p> required <code>overrides</code> <code>list[tuple]</code> <p>List of tuples for field overrides. Defaults to None.</p> <code>None</code> <code>options</code> <code>dict</code> <p>Additional request options. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pl.DataFrame: A Polars DataFrame containing the requested historical data.</p> <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If there is an issue with the Bloomberg session.</p> <code>ValueError</code> <p>If the request parameters are invalid.</p> Example <p>Fetch historical closing prices for TLT:</p> <pre><code>from datetime import date\nfrom polars_bloomberg import BQuery\n\nwith BQuery() as bq:\n    df = bq.bdh(\n        [\"TLT US Equity\"],\n        [\"PX_LAST\"],\n        start_date=date(2019, 1, 1),\n        end_date=date(2019, 1, 7),\n    )\nprint(df)\n</code></pre> <p>Expected output: <pre><code>shape: (4, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 security      \u2506 date       \u2506 PX_LAST \u2502\n\u2502 ---           \u2506 ---        \u2506 ---     \u2502\n\u2502 str           \u2506 date       \u2506 f64     \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 TLT US Equity \u2506 2019-01-02 \u2506 122.15  \u2502\n\u2502 TLT US Equity \u2506 2019-01-03 \u2506 123.54  \u2502\n\u2502 TLT US Equity \u2506 2019-01-04 \u2506 122.11  \u2502\n\u2502 TLT US Equity \u2506 2019-01-07 \u2506 121.75  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> Source code in <code>polars_bloomberg\\plbbg.py</code> <pre><code>def bdh(\n    self,\n    securities: list[str],\n    fields: list[str],\n    start_date: date,\n    end_date: date,\n    overrides: list[tuple] | None = None,\n    options: dict | None = None,\n) -&gt; pl.DataFrame:\n    \"\"\"Bloomberg Data History, equivalent to Excel BDH() function.\n\n    Fetch historical data for given securities and fields between dates.\n\n    Args:\n        securities (list[str]): List of security identifiers (e.g., 'AAPL US Equity').\n        fields (list[str]): List of data fields to retrieve (e.g., 'PX_LAST').\n        start_date (date): Start date for the historical data.\n        end_date (date): End date for the historical data.\n        overrides (list[tuple], optional): List of tuples for field overrides. Defaults to None.\n        options (dict, optional): Additional request options. Defaults to None.\n\n    Returns:\n        pl.DataFrame: A Polars DataFrame containing the requested historical data.\n\n    Raises:\n        ConnectionError: If there is an issue with the Bloomberg session.\n        ValueError: If the request parameters are invalid.\n\n    Example:\n        Fetch historical closing prices for TLT:\n\n        ```python\n        from datetime import date\n        from polars_bloomberg import BQuery\n\n        with BQuery() as bq:\n            df = bq.bdh(\n                [\"TLT US Equity\"],\n                [\"PX_LAST\"],\n                start_date=date(2019, 1, 1),\n                end_date=date(2019, 1, 7),\n            )\n        print(df)\n        ```\n\n        Expected output:\n        ```python\n        shape: (4, 3)\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502 security      \u2506 date       \u2506 PX_LAST \u2502\n        \u2502 ---           \u2506 ---        \u2506 ---     \u2502\n        \u2502 str           \u2506 date       \u2506 f64     \u2502\n        \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        \u2502 TLT US Equity \u2506 2019-01-02 \u2506 122.15  \u2502\n        \u2502 TLT US Equity \u2506 2019-01-03 \u2506 123.54  \u2502\n        \u2502 TLT US Equity \u2506 2019-01-04 \u2506 122.11  \u2502\n        \u2502 TLT US Equity \u2506 2019-01-07 \u2506 121.75  \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        ```\n\n    \"\"\"  # noqa: E501\n    request = self._create_request(\n        \"HistoricalDataRequest\", securities, fields, overrides, options\n    )\n    request.set(\"startDate\", start_date.strftime(\"%Y%m%d\"))\n    request.set(\"endDate\", end_date.strftime(\"%Y%m%d\"))\n    responses = self._send_request(request)\n    data = self._parse_bdh_responses(responses, fields)\n    return pl.DataFrame(data, infer_schema_length=None)\n</code></pre>"},{"location":"api/#polars_bloomberg.BQuery.bdib","title":"<code>bdib(security, event_type, interval, start_datetime, end_datetime, overrides=None, options=None)</code>","text":"<p>Fetch intraday bars from Bloomberg, mirroring Excel's BDIB() function.</p> <p>Parameters:</p> Name Type Description Default <code>security</code> <code>str</code> <p>Instrument identifier (for example 'AAPL US Equity').</p> required <code>event_type</code> <code>str</code> <p>One of TRADE, BID, ASK, BEST_BID, BEST_ASK.</p> required <code>interval</code> <code>int</code> <p>Bar length in minutes (1-1440).</p> required <code>start_datetime</code> <code>datetime</code> <p>First bar timestamp; naive vals are treated as UTC tz-aware values are converted to UTC before the request is sent.</p> required <code>end_datetime</code> <code>datetime</code> <p>Last bar timestamp; handled same way as start_dtm</p> required <code>overrides</code> <code>Sequence | None</code> <p>Sequence of (field, value) overrides.</p> <code>None</code> <code>options</code> <code>dict | None</code> <p>Additional Bloomberg request options.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pl.DataFrame: Bars sorted by security/time with columns ['security', 'time', 'open', 'high', 'low', 'close', 'volume', 'numEvents', 'value']. Bloomberg emits <code>time</code> in UTC and the DataFrame preserves that timezone.</p> Example <pre><code>from datetime import datetime\nfrom polars_bloomberg import BQuery\n\nwith BQuery() as bq:\n    df = bq.bdib(\n        \"OMX Index\",\n        event_type=\"TRADE\",\n        interval=60,\n        start_datetime=datetime(2025, 11, 5),\n        end_datetime=datetime(2025, 11, 6),\n    )\n    print(df)\n</code></pre> <p>Expected output: <pre><code>shape: (4, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 security  \u2506 time         \u2506 open     \u2506 high     \u2506 \u2026 \u2506 close    \u2506 volume \u2506 numEvents \u2506 value \u2502\n\u2502 ---       \u2506 ---          \u2506 ---      \u2506 ---      \u2506   \u2506 ---      \u2506 ---    \u2506 ---       \u2506 ---   \u2502\n\u2502 str       \u2506 datetime[\u03bcs] \u2506 f64      \u2506 f64      \u2506   \u2506 f64      \u2506 i64    \u2506 i64       \u2506 f64   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 OMX Index \u2506 2025-11-05   \u2506 2726.603 \u2506 2742.014 \u2506 \u2026 \u2506 2739.321 \u2506 0      \u2506 3591      \u2506 0.0   \u2502\n\u2502           \u2506 08:00:00     \u2506          \u2506          \u2506   \u2506          \u2506        \u2506           \u2506       \u2502\n\u2502 OMX Index \u2506 2025-11-05   \u2506 2739.466 \u2506 2739.706 \u2506 \u2026 \u2506 2733.836 \u2506 0      \u2506 3600      \u2506 0.0   \u2502\n\u2502           \u2506 09:00:00     \u2506          \u2506          \u2506   \u2506          \u2506        \u2506           \u2506       \u2502\n\u2502 OMX Index \u2506 2025-11-05   \u2506 2733.747 \u2506 2734.827 \u2506 \u2026 \u2506 2731.724 \u2506 0      \u2506 3600      \u2506 0.0   \u2502\n\u2502           \u2506 10:00:00     \u2506          \u2506          \u2506   \u2506          \u2506        \u2506           \u2506       \u2502\n\u2502 OMX Index \u2506 2025-11-05   \u2506 2731.721 \u2506 2742.015 \u2506 \u2026 \u2506 2741.185 \u2506 0      \u2506 3600      \u2506 0.0   \u2502\n\u2502           \u2506 11:00:00     \u2506          \u2506          \u2506   \u2506          \u2506        \u2506           \u2506       \u2502\n\u2502 OMX Index \u2506 2025-11-05   \u2506 2741.256 \u2506 2747.291 \u2506 \u2026 \u2506 2747.291 \u2506 0      \u2506 3600      \u2506 0.0   \u2502\n\u2502           \u2506 12:00:00     \u2506          \u2506          \u2506   \u2506          \u2506        \u2506           \u2506       \u2502\n\u2502 OMX Index \u2506 2025-11-05   \u2506 2747.291 \u2506 2748.815 \u2506 \u2026 \u2506 2748.287 \u2506 0      \u2506 3600      \u2506 0.0   \u2502\n\u2502           \u2506 13:00:00     \u2506          \u2506          \u2506   \u2506          \u2506        \u2506           \u2506       \u2502\n\u2502 OMX Index \u2506 2025-11-05   \u2506 2748.273 \u2506 2752.301 \u2506 \u2026 \u2506 2752.181 \u2506 0      \u2506 3600      \u2506 0.0   \u2502\n\u2502           \u2506 14:00:00     \u2506          \u2506          \u2506   \u2506          \u2506        \u2506           \u2506       \u2502\n\u2502 OMX Index \u2506 2025-11-05   \u2506 2752.181 \u2506 2758.978 \u2506 \u2026 \u2506 2752.495 \u2506 0      \u2506 3600      \u2506 0.0   \u2502\n\u2502           \u2506 15:00:00     \u2506          \u2506          \u2506   \u2506          \u2506        \u2506           \u2506       \u2502\n\u2502 OMX Index \u2506 2025-11-05   \u2506 2752.402 \u2506 2752.85  \u2506 \u2026 \u2506 2751.404 \u2506 0      \u2506 2100      \u2506 0.0   \u2502\n\u2502           \u2506 16:00:00     \u2506          \u2506          \u2506   \u2506          \u2506        \u2506           \u2506       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> Source code in <code>polars_bloomberg\\plbbg.py</code> <pre><code>def bdib(  # noqa: PLR0913\n    self,\n    security: str,\n    event_type: str,\n    interval: int,\n    start_datetime: datetime,\n    end_datetime: datetime,\n    overrides: Sequence | None = None,\n    options: dict | None = None,\n) -&gt; pl.DataFrame:\n    \"\"\"Fetch intraday bars from Bloomberg, mirroring Excel's BDIB() function.\n\n    Args:\n        security (str): Instrument identifier (for example 'AAPL US Equity').\n        event_type (str): One of TRADE, BID, ASK, BEST_BID, BEST_ASK.\n        interval (int): Bar length in minutes (1-1440).\n        start_datetime (datetime): First bar timestamp; naive vals are treated as UTC\n            tz-aware values are converted to UTC before the request is sent.\n        end_datetime (datetime): Last bar timestamp; handled same way as start_dtm\n        overrides (Sequence | None, optional): Sequence of (field, value) overrides.\n        options (dict | None, optional): Additional Bloomberg request options.\n\n    Returns:\n        pl.DataFrame: Bars sorted by security/time with columns\n            ['security', 'time', 'open', 'high', 'low', 'close', 'volume',\n            'numEvents', 'value']. Bloomberg emits `time` in UTC and the DataFrame\n            preserves that timezone.\n\n    Example:\n        ```python\n        from datetime import datetime\n        from polars_bloomberg import BQuery\n\n        with BQuery() as bq:\n            df = bq.bdib(\n                \"OMX Index\",\n                event_type=\"TRADE\",\n                interval=60,\n                start_datetime=datetime(2025, 11, 5),\n                end_datetime=datetime(2025, 11, 6),\n            )\n            print(df)\n        ```\n\n         Expected output:\n        ```python\n        shape: (4, 3)\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502 security  \u2506 time         \u2506 open     \u2506 high     \u2506 \u2026 \u2506 close    \u2506 volume \u2506 numEvents \u2506 value \u2502\n        \u2502 ---       \u2506 ---          \u2506 ---      \u2506 ---      \u2506   \u2506 ---      \u2506 ---    \u2506 ---       \u2506 ---   \u2502\n        \u2502 str       \u2506 datetime[\u03bcs] \u2506 f64      \u2506 f64      \u2506   \u2506 f64      \u2506 i64    \u2506 i64       \u2506 f64   \u2502\n        \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        \u2502 OMX Index \u2506 2025-11-05   \u2506 2726.603 \u2506 2742.014 \u2506 \u2026 \u2506 2739.321 \u2506 0      \u2506 3591      \u2506 0.0   \u2502\n        \u2502           \u2506 08:00:00     \u2506          \u2506          \u2506   \u2506          \u2506        \u2506           \u2506       \u2502\n        \u2502 OMX Index \u2506 2025-11-05   \u2506 2739.466 \u2506 2739.706 \u2506 \u2026 \u2506 2733.836 \u2506 0      \u2506 3600      \u2506 0.0   \u2502\n        \u2502           \u2506 09:00:00     \u2506          \u2506          \u2506   \u2506          \u2506        \u2506           \u2506       \u2502\n        \u2502 OMX Index \u2506 2025-11-05   \u2506 2733.747 \u2506 2734.827 \u2506 \u2026 \u2506 2731.724 \u2506 0      \u2506 3600      \u2506 0.0   \u2502\n        \u2502           \u2506 10:00:00     \u2506          \u2506          \u2506   \u2506          \u2506        \u2506           \u2506       \u2502\n        \u2502 OMX Index \u2506 2025-11-05   \u2506 2731.721 \u2506 2742.015 \u2506 \u2026 \u2506 2741.185 \u2506 0      \u2506 3600      \u2506 0.0   \u2502\n        \u2502           \u2506 11:00:00     \u2506          \u2506          \u2506   \u2506          \u2506        \u2506           \u2506       \u2502\n        \u2502 OMX Index \u2506 2025-11-05   \u2506 2741.256 \u2506 2747.291 \u2506 \u2026 \u2506 2747.291 \u2506 0      \u2506 3600      \u2506 0.0   \u2502\n        \u2502           \u2506 12:00:00     \u2506          \u2506          \u2506   \u2506          \u2506        \u2506           \u2506       \u2502\n        \u2502 OMX Index \u2506 2025-11-05   \u2506 2747.291 \u2506 2748.815 \u2506 \u2026 \u2506 2748.287 \u2506 0      \u2506 3600      \u2506 0.0   \u2502\n        \u2502           \u2506 13:00:00     \u2506          \u2506          \u2506   \u2506          \u2506        \u2506           \u2506       \u2502\n        \u2502 OMX Index \u2506 2025-11-05   \u2506 2748.273 \u2506 2752.301 \u2506 \u2026 \u2506 2752.181 \u2506 0      \u2506 3600      \u2506 0.0   \u2502\n        \u2502           \u2506 14:00:00     \u2506          \u2506          \u2506   \u2506          \u2506        \u2506           \u2506       \u2502\n        \u2502 OMX Index \u2506 2025-11-05   \u2506 2752.181 \u2506 2758.978 \u2506 \u2026 \u2506 2752.495 \u2506 0      \u2506 3600      \u2506 0.0   \u2502\n        \u2502           \u2506 15:00:00     \u2506          \u2506          \u2506   \u2506          \u2506        \u2506           \u2506       \u2502\n        \u2502 OMX Index \u2506 2025-11-05   \u2506 2752.402 \u2506 2752.85  \u2506 \u2026 \u2506 2751.404 \u2506 0      \u2506 2100      \u2506 0.0   \u2502\n        \u2502           \u2506 16:00:00     \u2506          \u2506          \u2506   \u2506          \u2506        \u2506           \u2506       \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        ```\n\n    \"\"\"  # noqa: E501\n    request = self._create_intraday_bar_request(\n        security=security,\n        event_type=event_type,\n        interval=interval,\n        start_datetime=start_datetime,\n        end_datetime=end_datetime,\n        overrides=overrides,\n        options=options,\n    )\n    responses = self._send_request(request)\n    data = self._parse_bdib_responses(responses, fallback_security=security)\n    schema = {\n        \"security\": pl.Utf8,\n        \"time\": pl.Datetime,\n        \"open\": pl.Float64,\n        \"high\": pl.Float64,\n        \"low\": pl.Float64,\n        \"close\": pl.Float64,\n        \"volume\": pl.Int64,\n        \"numEvents\": pl.Int64,\n        \"value\": pl.Float64,\n    }\n    df = pl.DataFrame(data, schema=schema, strict=False, infer_schema_length=None)\n    return df.sort([\"security\", \"time\"]) if not df.is_empty() else df\n</code></pre>"},{"location":"api/#polars_bloomberg.BQuery.bdp","title":"<code>bdp(securities, fields, overrides=None, options=None)</code>","text":"<p>Bloomberg Data Point, equivalent to Excel BDP() function.</p> <p>Fetch reference data for given securities and fields.</p> <p>Parameters:</p> Name Type Description Default <code>securities</code> <code>list[str]</code> <p>List of security identifiers (e.g. 'AAPL US Equity').</p> required <code>fields</code> <code>list[str]</code> <p>List of data fields to retrieve (e.g., 'PX_LAST').</p> required <code>overrides</code> <code>list[tuple]</code> <p>List of tuples for field overrides. Defaults to None.</p> <code>None</code> <code>options</code> <code>dict</code> <p>Additional request options. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pl.DataFrame: A Polars DataFrame containing the requested reference data.</p> <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If there is an issue with the Bloomberg session.</p> <code>ValueError</code> <p>If the request parameters are invalid.</p> Example <p>Fetch last price for Apple and Microsoft stocks:</p> <pre><code>from polars_bloomberg import BQuery\n\nwith BQuery() as bq:\n    df = bq.bdp(['AAPL US Equity', 'MSFT US Equity'], ['PX_LAST'])\nprint(df)\n</code></pre> <p>Expected output: <pre><code>shape: (2, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 security       \u2506 PX_LAST  \u2502\n\u2502 ---            \u2506 ---      \u2502\n\u2502 str            \u2506 f64      \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 AAPL US Equity \u2506 171.32   \u2502\n\u2502 MSFT US Equity \u2506 232.33   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> Source code in <code>polars_bloomberg\\plbbg.py</code> <pre><code>def bdp(\n    self,\n    securities: list[str],\n    fields: list[str],\n    overrides: list[tuple] | None = None,\n    options: dict | None = None,\n) -&gt; pl.DataFrame:\n    \"\"\"Bloomberg Data Point, equivalent to Excel BDP() function.\n\n    Fetch reference data for given securities and fields.\n\n    Args:\n        securities (list[str]): List of security identifiers (e.g. 'AAPL US Equity').\n        fields (list[str]): List of data fields to retrieve (e.g., 'PX_LAST').\n        overrides (list[tuple], optional): List of tuples for field overrides. Defaults to None.\n        options (dict, optional): Additional request options. Defaults to None.\n\n    Returns:\n        pl.DataFrame: A Polars DataFrame containing the requested reference data.\n\n    Raises:\n        ConnectionError: If there is an issue with the Bloomberg session.\n        ValueError: If the request parameters are invalid.\n\n    Example:\n        Fetch last price for Apple and Microsoft stocks:\n\n        ```python\n        from polars_bloomberg import BQuery\n\n        with BQuery() as bq:\n            df = bq.bdp(['AAPL US Equity', 'MSFT US Equity'], ['PX_LAST'])\n        print(df)\n        ```\n\n        Expected output:\n        ```python\n        shape: (2, 2)\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502 security       \u2506 PX_LAST  \u2502\n        \u2502 ---            \u2506 ---      \u2502\n        \u2502 str            \u2506 f64      \u2502\n        \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        \u2502 AAPL US Equity \u2506 171.32   \u2502\n        \u2502 MSFT US Equity \u2506 232.33   \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        ```\n\n    \"\"\"  # noqa: E501\n    request = self._create_request(\n        \"ReferenceDataRequest\", securities, fields, overrides, options\n    )\n    responses = self._send_request(request)\n    data = self._parse_bdp_responses(responses, fields)\n    return pl.DataFrame(data)\n</code></pre>"},{"location":"api/#polars_bloomberg.BQuery.bql","title":"<code>bql(expression)</code>","text":"<p>Execute a Bloomberg Query Language (BQL) query.</p> <p>BQL is Bloomberg's domain-specific language for complex financial queries. It allows for advanced data retrieval, screening, and analysis.</p> <p>Parameters:</p> Name Type Description Default <code>expression</code> <code>str</code> <p>The BQL query expression to execute. Can include functions like get(), let(), for(), filter(), etc.</p> required <p>Returns:</p> Name Type Description <code>BqlResult</code> <code>BqlResult</code> <p>An object containing: - List of Polars DataFrames (one for each item in BQL get statement) - Helper methods like combine() to merge DataFrames on common columns Returns empty result if BQL syntax is invalid (error is logged).</p> <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If there is an issue with the Bloomberg session.</p> Example <p>Simple query to fetch last price:</p> <pre><code>from polars_bloomberg import BQuery\n\nwith BQuery() as bq:\n    # Get last price for multiple securities\n    result = bq.bql(\"get(px_last) for(['IBM US Equity', 'MSFT US Equity'])\")\n    df = result.combine()\n    print(df)\n</code></pre> <p>Expected output: <pre><code>shape: (2, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 ID            \u2506 PX_LAST \u2502\n\u2502 ---           \u2506 ---     \u2502\n\u2502 str           \u2506 f64     \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 AAPL US Equity\u2506 150.25  \u2502\n\u2502 MSFT US Equity\u2506 250.80  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> <p>Access individual DataFrames: <pre><code>&gt;&gt;&gt; df_px_last = result[0]\n&gt;&gt;&gt; print(df_px_last)\nshape: (2, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 ID            \u2506 PX_LAST \u2502\n\u2502 ---           \u2506 ---     \u2502\n\u2502 str           \u2506 f64     \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 AAPL US Equity\u2506 150.25  \u2502\n\u2502 MSFT US Equity\u2506 250.80  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> Fetch multiple fields and combine results: <pre><code>&gt;&gt;&gt; result = bq.bql(\"get(px_last, px_volume) for('AAPL US Equity')\")\n&gt;&gt;&gt; df_combined = result.combine()\n&gt;&gt;&gt; print(df_combined)\nshape: (1, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 ID            \u2506 PX_LAST \u2506 PX_VOLUME  \u2502\n\u2502 ---           \u2506 ---     \u2506 ---        \u2502\n\u2502 str           \u2506 f64     \u2506 f64        \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 AAPL US Equity\u2506 150.25  \u2506 30000000.0 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> Iterate over individual DataFrames: <pre><code>&gt;&gt;&gt; for df in result:\n...     print(df)\n</code></pre></p> Source code in <code>polars_bloomberg\\plbbg.py</code> <pre><code>def bql(self, expression: str) -&gt; BqlResult:\n    \"\"\"Execute a Bloomberg Query Language (BQL) query.\n\n    BQL is Bloomberg's domain-specific language for complex financial queries. It allows\n    for advanced data retrieval, screening, and analysis.\n\n    Args:\n        expression (str): The BQL query expression to execute. Can include functions like\n            get(), let(), for(), filter(), etc.\n\n    Returns:\n        BqlResult: An object containing:\n            - List of Polars DataFrames (one for each item in BQL get statement)\n            - Helper methods like combine() to merge DataFrames on common columns\n            Returns empty result if BQL syntax is invalid (error is logged).\n\n    Raises:\n        ConnectionError: If there is an issue with the Bloomberg session.\n\n    Example:\n        Simple query to fetch last price:\n\n        ```python\n        from polars_bloomberg import BQuery\n\n        with BQuery() as bq:\n            # Get last price for multiple securities\n            result = bq.bql(\"get(px_last) for(['IBM US Equity', 'MSFT US Equity'])\")\n            df = result.combine()\n            print(df)\n        ```\n\n        Expected output:\n        ```python\n        shape: (2, 4)\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502 ID            \u2506 PX_LAST \u2502\n        \u2502 ---           \u2506 ---     \u2502\n        \u2502 str           \u2506 f64     \u2502\n        \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        \u2502 AAPL US Equity\u2506 150.25  \u2502\n        \u2502 MSFT US Equity\u2506 250.80  \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        ```\n\n        Access individual DataFrames:\n        ```python\n        &gt;&gt;&gt; df_px_last = result[0]\n        &gt;&gt;&gt; print(df_px_last)\n        shape: (2, 2)\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502 ID            \u2506 PX_LAST \u2502\n        \u2502 ---           \u2506 ---     \u2502\n        \u2502 str           \u2506 f64     \u2502\n        \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        \u2502 AAPL US Equity\u2506 150.25  \u2502\n        \u2502 MSFT US Equity\u2506 250.80  \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        ```\n        Fetch multiple fields and combine results:\n        ```python\n        &gt;&gt;&gt; result = bq.bql(\"get(px_last, px_volume) for('AAPL US Equity')\")\n        &gt;&gt;&gt; df_combined = result.combine()\n        &gt;&gt;&gt; print(df_combined)\n        shape: (1, 3)\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502 ID            \u2506 PX_LAST \u2506 PX_VOLUME  \u2502\n        \u2502 ---           \u2506 ---     \u2506 ---        \u2502\n        \u2502 str           \u2506 f64     \u2506 f64        \u2502\n        \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        \u2502 AAPL US Equity\u2506 150.25  \u2506 30000000.0 \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        ```\n        Iterate over individual DataFrames:\n        ```python\n        &gt;&gt;&gt; for df in result:\n        ...     print(df)\n        ```\n\n    \"\"\"  # noqa: E501\n    request = self._create_bql_request(expression)\n    responses = self._send_request(request)\n    tables = self._parse_bql_responses(responses)\n    dataframes = [\n        pl.DataFrame(table.data, schema=table.schema, strict=True)\n        for table in tables\n    ]\n    names = [table.name for table in tables]\n    return BqlResult(dataframes, names)\n</code></pre>"},{"location":"api/#polars_bloomberg.BQuery.bsrch","title":"<code>bsrch(domain, overrides=None, options=None)</code>","text":"<p>Bloomberg SRCH (search) via ExcelGetGridRequest on //blp/exrsvc.</p> <p>Parameters:</p> Name Type Description Default <code>domain</code> <code>str</code> <p>Domain string, e.g. <code>\\\"FI:SRCHEX.@COCO\\\"</code>.</p> required <code>overrides</code> <code>dict[str, Any] | None</code> <p>Optional override map (e.g. <code>{\\\"LIMIT\\\": 20000}</code>).</p> <code>None</code> <code>options</code> <code>dict | None</code> <p>Additional request options applied directly to the request.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pl.DataFrame with one row per search record and columns from the grid.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>When Bloomberg returns an error string in GridResponse.</p> <code>TimeoutError / ConnectionError</code> <p>As surfaced by the session helpers.</p> Example <p>Fetch Contingent COnvertible bonds based on Example Search @COCO For sake of example limit number of bonds to two</p> <pre><code>from polars_bloomberg import BQuery\n\nwith BQuery() as bq:\n    df = bq.bsrch(\"FI:SRCHEX.@COCO\", {\"LIMIT\": 2})\n    print(df)\n</code></pre> <p>Expected output: <pre><code>BSRCH response reached internal limit; consider using LIMIT override.\nshape: (2, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 id            \u2502\n\u2502 ---           \u2502\n\u2502 str           \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 DA785784 Corp \u2502\n\u2502 DA773901 Corp \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> Source code in <code>polars_bloomberg\\plbbg.py</code> <pre><code>def bsrch(\n    self,\n    domain: str,\n    overrides: dict[str, Any] | None = None,\n    options: dict | None = None,\n) -&gt; pl.DataFrame:\n    r\"\"\"Bloomberg SRCH (search) via ExcelGetGridRequest on //blp/exrsvc.\n\n    Args:\n        domain: Domain string, e.g. ``\\\"FI:SRCHEX.@COCO\\\"``.\n        overrides: Optional override map (e.g. ``{\\\"LIMIT\\\": 20000}``).\n        options: Additional request options applied directly to the request.\n\n    Returns:\n        pl.DataFrame with one row per search record and columns from the grid.\n\n    Raises:\n        ValueError: When Bloomberg returns an error string in GridResponse.\n        TimeoutError/ConnectionError: As surfaced by the session helpers.\n\n    Example:\n        Fetch Contingent COnvertible bonds based on Example Search @COCO\n        For sake of example limit number of bonds to two\n\n        ```python\n        from polars_bloomberg import BQuery\n\n        with BQuery() as bq:\n            df = bq.bsrch(\"FI:SRCHEX.@COCO\", {\"LIMIT\": 2})\n            print(df)\n        ```\n\n        Expected output:\n        ```python\n        BSRCH response reached internal limit; consider using LIMIT override.\n        shape: (2, 1)\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502 id            \u2502\n        \u2502 ---           \u2502\n        \u2502 str           \u2502\n        \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        \u2502 DA785784 Corp \u2502\n        \u2502 DA773901 Corp \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        ```\n\n    \"\"\"\n    request = self._create_bsrch_request(domain, overrides, options)\n    responses = self._send_request(request)\n    limit_applied = bool(overrides and \"LIMIT\" in overrides)\n    rows = self._parse_bsrch_responses(responses, limit_applied=limit_applied)\n    return pl.DataFrame(rows, infer_schema_length=None, strict=False)\n</code></pre>"},{"location":"api/#polars_bloomberg.BqlResult","title":"<code>polars_bloomberg.BqlResult</code>  <code>dataclass</code>","text":"<p>Holds the result of a BQL query as a list of Polars DataFrames.</p> <p>This class encapsulates the results of a Bloomberg Query Language (BQL) query, providing methods to access and manipulate the data.</p> <p>Attributes:</p> Name Type Description <code>dataframes</code> <code>list[DataFrame]</code> <p>List of query result dataframes.</p> <code>names</code> <code>list[str]</code> <p>List of data-item names corresponding to dataframes.</p> Example <p>Execute a BQL query and combine the results:</p> <pre><code>from polars_bloomberg import BQuery\n\nwith BQuery() as bq:\n    result = bq.bql(\"get(px_last) for(['IBM US Equity', 'MSFT US Equity'])\")\n    df = result.combine()\n    print(df)\n</code></pre> <p>Expected output: <pre><code>shape: (2, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 ID            \u2506 PX_LAST \u2502\n\u2502 ---           \u2506 ---     \u2502\n\u2502 str           \u2506 f64     \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 IBM US Equity \u2506 125.34  \u2502\n\u2502 MSFT US Equity\u2506 232.33  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> <p>Iterate over the list of DataFrames:</p> <pre><code>for df in result:\n    print(df)\n</code></pre> <p>Access individual DataFrames by index:</p> <pre><code>first_df = result[0]\nprint(first_df)\n</code></pre> <p>Get the number of DataFrames:</p> <pre><code>num_dfs = len(result)\nprint(f\"Number of DataFrames: {num_dfs}\")\n</code></pre> <p>Methods:</p> Name Description <code>combine</code> <p>Combine all dataframes into one by joining on common columns.</p> Source code in <code>polars_bloomberg\\plbbg.py</code> <pre><code>@dataclass\nclass BqlResult:\n    \"\"\"Holds the result of a BQL query as a list of Polars DataFrames.\n\n    This class encapsulates the results of a Bloomberg Query Language (BQL) query,\n    providing methods to access and manipulate the data.\n\n    Attributes:\n        dataframes (list[pl.DataFrame]): List of query result dataframes.\n        names (list[str]): List of data-item names corresponding to dataframes.\n\n    Example:\n        Execute a BQL query and combine the results:\n\n        ```python\n        from polars_bloomberg import BQuery\n\n        with BQuery() as bq:\n            result = bq.bql(\"get(px_last) for(['IBM US Equity', 'MSFT US Equity'])\")\n            df = result.combine()\n            print(df)\n        ```\n\n        Expected output:\n        ```python\n        shape: (2, 4)\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502 ID            \u2506 PX_LAST \u2502\n        \u2502 ---           \u2506 ---     \u2502\n        \u2502 str           \u2506 f64     \u2502\n        \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        \u2502 IBM US Equity \u2506 125.34  \u2502\n        \u2502 MSFT US Equity\u2506 232.33  \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        ```\n\n        Iterate over the list of DataFrames:\n\n        ```python\n        for df in result:\n            print(df)\n        ```\n\n        Access individual DataFrames by index:\n\n        ```python\n        first_df = result[0]\n        print(first_df)\n        ```\n\n        Get the number of DataFrames:\n\n        ```python\n        num_dfs = len(result)\n        print(f\"Number of DataFrames: {num_dfs}\")\n        ```\n\n    Methods:\n        combine: Combine all dataframes into one by joining on common columns.\n\n    \"\"\"\n\n    dataframes: list[pl.DataFrame]\n    names: list[str]\n\n    def combine(self) -&gt; pl.DataFrame:\n        \"\"\"Combine all dataframes into one by joining on common columns.\n\n        This method merges all the DataFrames in the `dataframes` attribute into a single\n        DataFrame by performing a full join on the common columns. If no common columns\n        are found, it raises a ValueError.\n\n        Returns:\n            pl.DataFrame: Combined dataframe joined on common columns.\n\n        Raises:\n            ValueError: If no common columns exist or no dataframes are present.\n\n        Example:\n            Combine results of a BQL query:\n\n            ```python\n            from polars_bloomberg import BQuery\n\n            with BQuery() as bq:\n                result = bq.bql(\"get(px_last, px_volume) for(['AAPL US Equity', 'MSFT US Equity'])\")\n                df = result.combine()\n                print(df)\n            ```\n\n            Expected output:\n            ```python\n            shape: (2, 3)\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u2502 ID             \u2506 PX_LAST  \u2506 PX_VOLUME  \u2502\n            \u2502 ---            \u2506 ---      \u2506 ---        \u2502\n            \u2502 str            \u2506 f64      \u2506 f64        \u2502\n            \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n            \u2502 AAPL US Equity \u2506 150.25   \u2506 30000000.0 \u2502\n            \u2502 MSFT US Equity \u2506 250.80   \u2506 20000000.0 \u2502\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            ```\n\n            Handle no common columns:\n\n            ```python\n            with BQuery() as bq:\n                result = bq.bql(\"get(px_last) for(['AAPL US Equity'])\")\n                try:\n                    df = result.combine()\n                except ValueError as e:\n                    print(e)\n            ```\n\n            Expected output:\n            ```\n            No common columns found to join on.\n            ```\n\n        \"\"\"  # noqa: E501\n        if not self.dataframes:\n            raise ValueError(\"No DataFrames to combine.\")\n\n        result = self.dataframes[0]  # Initialize with the first DataFrame\n        for df in self.dataframes[1:]:\n            common_cols = set(result.columns) &amp; set(df.columns)\n            if not common_cols:\n                raise ValueError(\"No common columns found to join on.\")\n            result = result.join(df, on=list(common_cols), how=\"full\", coalesce=True)\n        return result\n\n    def __getitem__(self, idx: int) -&gt; pl.DataFrame:\n        \"\"\"Access individual DataFrames by index.\"\"\"\n        return self.dataframes[idx]\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the number of dataframes.\"\"\"\n        return len(self.dataframes)\n\n    def __iter__(self):\n        \"\"\"Return an iterator over the dataframes.\"\"\"\n        return iter(self.dataframes)\n</code></pre>"},{"location":"api/#polars_bloomberg.BqlResult.__getitem__","title":"<code>__getitem__(idx)</code>","text":"<p>Access individual DataFrames by index.</p> Source code in <code>polars_bloomberg\\plbbg.py</code> <pre><code>def __getitem__(self, idx: int) -&gt; pl.DataFrame:\n    \"\"\"Access individual DataFrames by index.\"\"\"\n    return self.dataframes[idx]\n</code></pre>"},{"location":"api/#polars_bloomberg.BqlResult.__iter__","title":"<code>__iter__()</code>","text":"<p>Return an iterator over the dataframes.</p> Source code in <code>polars_bloomberg\\plbbg.py</code> <pre><code>def __iter__(self):\n    \"\"\"Return an iterator over the dataframes.\"\"\"\n    return iter(self.dataframes)\n</code></pre>"},{"location":"api/#polars_bloomberg.BqlResult.__len__","title":"<code>__len__()</code>","text":"<p>Return the number of dataframes.</p> Source code in <code>polars_bloomberg\\plbbg.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the number of dataframes.\"\"\"\n    return len(self.dataframes)\n</code></pre>"},{"location":"api/#polars_bloomberg.BqlResult.combine","title":"<code>combine()</code>","text":"<p>Combine all dataframes into one by joining on common columns.</p> <p>This method merges all the DataFrames in the <code>dataframes</code> attribute into a single DataFrame by performing a full join on the common columns. If no common columns are found, it raises a ValueError.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pl.DataFrame: Combined dataframe joined on common columns.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no common columns exist or no dataframes are present.</p> Example <p>Combine results of a BQL query:</p> <pre><code>from polars_bloomberg import BQuery\n\nwith BQuery() as bq:\n    result = bq.bql(\"get(px_last, px_volume) for(['AAPL US Equity', 'MSFT US Equity'])\")\n    df = result.combine()\n    print(df)\n</code></pre> <p>Expected output: <pre><code>shape: (2, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 ID             \u2506 PX_LAST  \u2506 PX_VOLUME  \u2502\n\u2502 ---            \u2506 ---      \u2506 ---        \u2502\n\u2502 str            \u2506 f64      \u2506 f64        \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 AAPL US Equity \u2506 150.25   \u2506 30000000.0 \u2502\n\u2502 MSFT US Equity \u2506 250.80   \u2506 20000000.0 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> <p>Handle no common columns:</p> <pre><code>with BQuery() as bq:\n    result = bq.bql(\"get(px_last) for(['AAPL US Equity'])\")\n    try:\n        df = result.combine()\n    except ValueError as e:\n        print(e)\n</code></pre> <p>Expected output: <pre><code>No common columns found to join on.\n</code></pre></p> Source code in <code>polars_bloomberg\\plbbg.py</code> <pre><code>def combine(self) -&gt; pl.DataFrame:\n    \"\"\"Combine all dataframes into one by joining on common columns.\n\n    This method merges all the DataFrames in the `dataframes` attribute into a single\n    DataFrame by performing a full join on the common columns. If no common columns\n    are found, it raises a ValueError.\n\n    Returns:\n        pl.DataFrame: Combined dataframe joined on common columns.\n\n    Raises:\n        ValueError: If no common columns exist or no dataframes are present.\n\n    Example:\n        Combine results of a BQL query:\n\n        ```python\n        from polars_bloomberg import BQuery\n\n        with BQuery() as bq:\n            result = bq.bql(\"get(px_last, px_volume) for(['AAPL US Equity', 'MSFT US Equity'])\")\n            df = result.combine()\n            print(df)\n        ```\n\n        Expected output:\n        ```python\n        shape: (2, 3)\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502 ID             \u2506 PX_LAST  \u2506 PX_VOLUME  \u2502\n        \u2502 ---            \u2506 ---      \u2506 ---        \u2502\n        \u2502 str            \u2506 f64      \u2506 f64        \u2502\n        \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        \u2502 AAPL US Equity \u2506 150.25   \u2506 30000000.0 \u2502\n        \u2502 MSFT US Equity \u2506 250.80   \u2506 20000000.0 \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        ```\n\n        Handle no common columns:\n\n        ```python\n        with BQuery() as bq:\n            result = bq.bql(\"get(px_last) for(['AAPL US Equity'])\")\n            try:\n                df = result.combine()\n            except ValueError as e:\n                print(e)\n        ```\n\n        Expected output:\n        ```\n        No common columns found to join on.\n        ```\n\n    \"\"\"  # noqa: E501\n    if not self.dataframes:\n        raise ValueError(\"No DataFrames to combine.\")\n\n    result = self.dataframes[0]  # Initialize with the first DataFrame\n    for df in self.dataframes[1:]:\n        common_cols = set(result.columns) &amp; set(df.columns)\n        if not common_cols:\n            raise ValueError(\"No common columns found to join on.\")\n        result = result.join(df, on=list(common_cols), how=\"full\", coalesce=True)\n    return result\n</code></pre>"},{"location":"examples/credit/","title":"Credit Examples","text":"<p>\u00a9 2025 Marek Ozana</p> <p>These examples show how to use <code>polars-bloomberg</code> for credit bond analysis</p> <ul> <li> <p></p> <p>CET1 Capital vs Requirements and Trigger levels</p> <p>Compare bank capital vs its regulatory requirements and vs AT1 trigger levels</p> <p> Open</p> </li> <li> <p></p> <p>Bank Capital, Asset Quality and Profitability</p> <p>A guided view of three bank \"vital signs\": capital (CET1), asset quality (NPL), and profitability (ROE), shown as cross-bank averages with dispersion.</p> <p> Open</p> </li> <li> <p></p> <p>Equity Cushion vs Credit Spread Analysis</p> <p>Analyze the relationship between company equity cushion and its bonds credit spreads</p> <p> Open</p> </li> <li> <p></p> <p>AT1 Bond Valuation</p> <p>Explore pricing mechanics and risk sensitivities for Additional Tier 1 (AT1) bonds.</p> <p> Open</p> </li> <li> <p></p> <p>AT1 vs Credits Historical OAS per Rating</p> <p>Compare AT1 (CoCo) vs senior credit OAS by rating to highlight the persistent CoCo premium.</p> <p> Open</p> </li> </ul>","tags":["Credit","AT1","CoCo","BQL"]},{"location":"examples/credit/at1-valuation/","title":"AT1 Bond Valuation","text":"Out[1]: In\u00a0[2]: Copied! <pre># Gett bond data from BQL\nfrom polars_bloomberg import BQuery\n\nquery = \"\"\"\nlet(\n    #dur       = duration(duration_type=MODIFIED).value;\n    #rtg_bb    = bb_composite().value;\n    #zspread   = spread(spread_type=Z).value;\n    #be        = flt_spread().value;\n)\nget(ticker, #dur, #rtg_bb, #zspread, #be)\nfor(\n    filter(\n        bondsUniv(types='active', consolidateDuplicates=true),\n        ticker() in ['SHBASS', 'SEB', 'SWEDA', 'DANBNK', 'NDAFH', 'DNBNO']\n        and crncy() == 'USD'\n        and basel_iii_designation() == 'Additional Tier 1'\n    )\n)\n\"\"\"\n\nwith BQuery() as bq:\n    df = bq.bql(query).combine()\ndf.head(3)\n</pre> # Gett bond data from BQL from polars_bloomberg import BQuery  query = \"\"\" let(     #dur       = duration(duration_type=MODIFIED).value;     #rtg_bb    = bb_composite().value;     #zspread   = spread(spread_type=Z).value;     #be        = flt_spread().value; ) get(ticker, #dur, #rtg_bb, #zspread, #be) for(     filter(         bondsUniv(types='active', consolidateDuplicates=true),         ticker() in ['SHBASS', 'SEB', 'SWEDA', 'DANBNK', 'NDAFH', 'DNBNO']         and crncy() == 'USD'         and basel_iii_designation() == 'Additional Tier 1'     ) ) \"\"\"  with BQuery() as bq:     df = bq.bql(query).combine() df.head(3) Out[2]: shape: (3, 6)IDticker#dur#rtg_bb#zspread#bestrstrf64strf64f64\"YR472577 Corp\"\"DANBNK\"3.509404\"BBB-\"231.091119259.9\"BR069680 Corp\"\"SWEDA\"2.937217\"BBB\"270.448417286.4\"BP504077 Corp\"\"DANBNK\"0.394512\"BBB-\"154.481971338.7"},{"location":"examples/credit/at1-valuation/#at1-bond-valuation","title":"AT1 Bond Valuation\u00b6","text":"<p>\u00a9 2025 Marek Ozana</p> <p>This notebook is a small, opinionated workflow for relative value screening in the AT1 universe using polars-bloomberg and interactive Altair charts.</p> <p>We pull a bond universe (IDs, tickers, ratings, duration, back-end spread, z-spread) and then visualize how z-spread behaves as a function of:</p> <ul> <li>Back-end spread (BE) and</li> <li>Duration (Dur)</li> </ul> <p>Both views include a simple fit. Bonds above the trend line are \u201ccheap\u201d on that axis (wider than the model would suggest), and bonds below the line are \u201crich\u201d.</p> <p>The two scatter plots are linked: clicking a point in one chart highlights the same bond in the other view, making it easy to spot names that look cheap (or rich) in both dimensions.</p>"},{"location":"examples/credit/at1-vs-credits-oas/","title":"AT1 vs Credits Historical OAS per Rating","text":"Out[1]: In\u00a0[2]: Copied! <pre># Get historical median OAS spreads for IG, HY and AT1 bonds\n\nfrom polars_bloomberg import BQuery\n\nquery = \"\"\"\n    let(\n        #rng = range(2014-12-31, today(), frq='CM');\n        #sprd = spread(dates=#rng, fill=PREV, spread_type='OAS');\n        #is_coco = capital_contingent_security();\n        #month = MONTH(#sprd().DATE);\n        #year = YEAR(#sprd().DATE);\n\n        #oas = median(group(#sprd(), by=[bb_composite, #is_coco, #month, #year]));\n    )\n    get(#oas)\n    for(\n        filter(\n            members(['I31095 Index', 'LP01STAT Index', 'LP05STAT Index']),\n            bb_composite() in ['BBB', 'BBB-', 'BB+', 'BB']\n        )\n    )\n    preferences(dropCols=['ORIG_IDS'])\n\"\"\"\n\nwith BQuery() as bq:\n    df = bq.bql(query).combine()\ndf.tail(3)\n</pre> # Get historical median OAS spreads for IG, HY and AT1 bonds  from polars_bloomberg import BQuery  query = \"\"\"     let(         #rng = range(2014-12-31, today(), frq='CM');         #sprd = spread(dates=#rng, fill=PREV, spread_type='OAS');         #is_coco = capital_contingent_security();         #month = MONTH(#sprd().DATE);         #year = YEAR(#sprd().DATE);          #oas = median(group(#sprd(), by=[bb_composite, #is_coco, #month, #year]));     )     get(#oas)     for(         filter(             members(['I31095 Index', 'LP01STAT Index', 'LP05STAT Index']),             bb_composite() in ['BBB', 'BBB-', 'BB+', 'BB']         )     )     preferences(dropCols=['ORIG_IDS']) \"\"\"  with BQuery() as bq:     df = bq.bql(query).combine() df.tail(3) Out[2]: shape: (3, 7)ID#oasDATEBB_COMPOSITE#IS_COCO#MONTH#YEARstrf64datestrbooli64i64\"BBB:true:9.0:2023.0\"437.8331672023-09-30\"BBB\"true92023\"BBB:true:9.0:2024.0\"303.5008562024-09-30\"BBB\"true92024\"BBB:true:9.0:2025.0\"246.9926692025-09-30\"BBB\"true92025"},{"location":"examples/credit/at1-vs-credits-oas/#at1-vs-credits-historical-oas-per-rating","title":"AT1 vs Credits Historical OAS per Rating\u00b6","text":"<p>\u00a9 2025 Marek Ozana</p> <p>This notebook shows how to use polars-bloomberg to pull BQL history and compare option-adjusted spreads (OAS) between AT1 (CoCo) bonds and other (non-subordinated) credit, bucketed by rating. The BQL query is constructed to pull historical OAS by date, rating, and credit type (CoCo vs Credit). By controlling for credit risk via rating, we can isolate the \u201cAT1 premium\u201d and show that CoCo investors have historically earned additional spread even after adjusting for credit quality.</p> <p>We:</p> <ul> <li><p>Pull historical OAS for AT1 (CoCo) and senior credit across rating buckets</p> </li> <li><p>Chart the spread gap through time to highlight the persistent CoCo premium after rating adjustment</p> </li> </ul>"},{"location":"examples/credit/bank-CET1-vs-requirements/","title":"CET1 vs Requirements and AT1 Trigger levels","text":"Out[1]: In\u00a0[2]: Copied! <pre>from polars_bloomberg import BQuery\n\nquery = \"\"\"\nlet(\n    #cet1 = value(bs_tier1_com_equity_ratio, fundamentalTicker, mapby=LINEAGE);\n    #trigger = CAPITAL_TYPE_COCO_TRIGGER_LEVEL();\n    #req = value(bs_ce_tier_1_review(), fundamentalTicker, mapby=LINEAGE);\n)\nget(ticker, #cet1, #trigger, #req)\nfor(\n    filter(\n        members('I31095 Index'),\n        value(bs_tot_asset(currency='EUR') &gt; 105B, fundamentalTicker, mapby=LINEAGE)\n    )\n)\n\"\"\"\nwith BQuery() as bq:\n    res = bq.bql(query)\n\n# Combine on 'ID' column\ndf = res[0]\nfor idx, d in enumerate(res[1:], start=1):\n    suffix = f\"_{idx}\"\n    df = df.join(d, on=\"ID\", how=\"inner\", suffix=suffix)\ndf = df.drop_nulls()\ndf.head(3)\n</pre> from polars_bloomberg import BQuery  query = \"\"\" let(     #cet1 = value(bs_tier1_com_equity_ratio, fundamentalTicker, mapby=LINEAGE);     #trigger = CAPITAL_TYPE_COCO_TRIGGER_LEVEL();     #req = value(bs_ce_tier_1_review(), fundamentalTicker, mapby=LINEAGE); ) get(ticker, #cet1, #trigger, #req) for(     filter(         members('I31095 Index'),         value(bs_tot_asset(currency='EUR') &gt; 105B, fundamentalTicker, mapby=LINEAGE)     ) ) \"\"\" with BQuery() as bq:     res = bq.bql(query)  # Combine on 'ID' column df = res[0] for idx, d in enumerate(res[1:], start=1):     suffix = f\"_{idx}\"     df = df.join(d, on=\"ID\", how=\"inner\", suffix=suffix) df = df.drop_nulls() df.head(3)  Out[2]: shape: (3, 14)IDticker#cet1REVISION_DATEAS_OF_DATEPERIOD_END_DATESOURCE_ID#triggerMULTIPLIER#reqREVISION_DATE_3AS_OF_DATE_3PERIOD_END_DATE_3SOURCE_ID_3strstrf64datedatedatestrf64f64f64datedatedatestr\"ZM918892 Corp\"\"INTNED\"13.42025-10-302025-12-182025-09-30\"INGA NA Equity\"7.01.010.832025-10-302025-12-182025-09-30\"INGA NA Equity\"\"YV921889 Corp\"\"NDAFH\"15.92025-10-162025-12-182025-09-30\"NDA FH Equity\"5.1251.013.62025-10-162025-12-182025-09-30\"NDA FH Equity\"\"ZM198062 Corp\"\"ACAFP\"11.652025-10-302025-12-182025-09-30\"ACA FP Equity\"5.1251.08.22025-10-302025-12-182025-09-30\"ACA FP Equity\""},{"location":"examples/credit/bank-CET1-vs-requirements/#cet1-vs-requirements-and-at1-trigger-levels","title":"CET1 vs Requirements and AT1 Trigger levels\u00b6","text":"<p>\u00a9 2025 Marek Ozana</p> <p>This notebook is a small end-to-end example of using polars-bloomberg to pull regulatory capital metrics from BQL and chart them for a universe of European banks.</p> <p>We compare three CET1-related levels:</p> <ul> <li>CET1 (reported): the bank\u2019s current Common Equity Tier 1 ratio (what it has).</li> <li>CET1 requirement (\u201creview\u201d / SREP): the supervisory CET1 requirement level (what it must meet under review-driven requirements).</li> <li>AT1 trigger: the contractual CET1 trigger level associated with Additional Tier 1 (CoCo) instruments (the \u201coh no\u201d line where conversion/write-down mechanics may be activated).</li> </ul> <p>Interpretation:</p> <ul> <li>The vertical gap CET1 \u2212 requirement is \u201cheadroom\u201d against supervisory requirements.</li> <li>The gap CET1 \u2212 AT1 trigger is distance to the contractual AT1 trigger (not a regulatory buffer).</li> <li>Field definitions vary by jurisdiction and data source. Treat these as indicative and sanity-check against bank disclosures when precision matters.</li> </ul>"},{"location":"examples/credit/bank-capital-history/","title":"Bank Capital, Asset Quality and Profitability","text":"Out[1]: In\u00a0[2]: Copied! <pre>from polars_bloomberg import BQuery\n\nquery = \"\"\"\n    let(\n        #cet1 = bs_tier1_com_equity_ratio();\n        #npl = npls_to_total_loans();\n        #roe = normalized_roe();\n    )\n    get(ticker, #cet1, #npl, #roe)\n    for( MEMBERS('SX7E Index'))\n    with(fpt='Q', fpo=RANGE(-44Q,0Q))\n    preferences(dropCols=['AS_OF_DATE', 'REVISION_DATE'])\n\"\"\"\n\nwith BQuery() as bq:\n    res = bq.bql(query)\n\ndf = res.combine().drop_nulls()\nprint(df.head(3))\n</pre> from polars_bloomberg import BQuery  query = \"\"\"     let(         #cet1 = bs_tier1_com_equity_ratio();         #npl = npls_to_total_loans();         #roe = normalized_roe();     )     get(ticker, #cet1, #npl, #roe)     for( MEMBERS('SX7E Index'))     with(fpt='Q', fpo=RANGE(-44Q,0Q))     preferences(dropCols=['AS_OF_DATE', 'REVISION_DATE']) \"\"\"  with BQuery() as bq:     res = bq.bql(query)  df = res.combine().drop_nulls() print(df.head(3)) <pre>shape: (3, 6)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 ID            \u2506 ticker \u2506 #cet1 \u2506 PERIOD_END_DATE \u2506 #npl     \u2506 #roe     \u2502\n\u2502 ---           \u2506 ---    \u2506 ---   \u2506 ---             \u2506 ---      \u2506 ---      \u2502\n\u2502 str           \u2506 str    \u2506 f64   \u2506 date            \u2506 f64      \u2506 f64      \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 ABN NA Equity \u2506 ABN    \u2506 13.0  \u2506 2014-09-30      \u2506 2.189324 \u2506 5.439819 \u2502\n\u2502 ABN NA Equity \u2506 ABN    \u2506 14.1  \u2506 2014-12-31      \u2506 2.350165 \u2506 7.913441 \u2502\n\u2502 ABN NA Equity \u2506 ABN    \u2506 14.1  \u2506 2015-03-31      \u2506 2.172808 \u2506 9.199417 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre>"},{"location":"examples/credit/bank-capital-history/#bank-capital-asset-quality-and-profitability","title":"Bank Capital, Asset Quality and Profitability\u00b6","text":"<p>\u00a9 2025 Marek Ozana</p> <p>This notebook pulls quarterly fundamentals for a panel of large European banks and visualizes three core health signals:</p> <ul> <li>Capital (CET1 ratio): how much loss-absorbing capital banks have (higher is better)</li> <li>Asset quality (NPL ratio): how much of the loan book is non-performing (lower is better)</li> <li>Profitability (ROE): how efficiently equity is turned into earnings (higher is better)</li> </ul> <p>In the chart below, the line shows the cross-bank average over time and the shaded band shows the dispersion across banks. The big picture is simple: European banks are currently better capitalized, have cleaner loan books (lower NPLs), and are generating higher ROE than in most of the post-crisis period.</p>"},{"location":"examples/credit/equity-cushion-vs-spread/","title":"Credit Spreads vs Equity Cushion","text":"Out[1]: In\u00a0[\u00a0]: Copied! <pre># Get average spread (spread / duration) and equity cusion for all tickers\n\nfrom polars_bloomberg import BQuery\n\nquery = \"\"\"\n    let(\n        #dur = avg(group(duration(duration_type=MODIFIED),\n                         by=[ticker, bb_composite]));\n        #zspread = avg(group(spread(spread_type=Z),\n                             by=[ticker, bb_composite]));\n        #ev = avg(group(value(curr_entp_val(fpt='BT', fill='PREV'),\n                              fundamentalTicker,\n                              mapby=LINEAGE).value,\n                        by=[ticker, bb_composite]));\n        #ndebt = avg(group(value(net_debt(fpt='BT', fill='PREV'),\n                                 fundamentalTicker,\n                                 mapby=LINEAGE).value,\n                           by=[ticker, bb_composite]));\n        #ndebt2ebitda = avg(group(\n            value(net_debt_to_ebitda(fpt='BT', fill='PREV'),\n                  fundamentalTicker, mapby=LINEAGE).value,\n            by=[ticker, bb_composite]));\n        #eq_cushion = dropna((#ev - #ndebt) / #ev);\n        #spread_per_year = dropna(#zspread / #dur);\n    )\n    get(#eq_cushion, #spread_per_year, #ndebt2ebitda)\n    for(members(['LG30TRUU Index']))\n\"\"\"\n\nwith BQuery() as bq:\n    res = bq.bql(query)\n\ndf = res.combine().drop_nulls()\ndf.head(3)\n</pre> # Get average spread (spread / duration) and equity cusion for all tickers  from polars_bloomberg import BQuery  query = \"\"\"     let(         #dur = avg(group(duration(duration_type=MODIFIED),                          by=[ticker, bb_composite]));         #zspread = avg(group(spread(spread_type=Z),                              by=[ticker, bb_composite]));         #ev = avg(group(value(curr_entp_val(fpt='BT', fill='PREV'),                               fundamentalTicker,                               mapby=LINEAGE).value,                         by=[ticker, bb_composite]));         #ndebt = avg(group(value(net_debt(fpt='BT', fill='PREV'),                                  fundamentalTicker,                                  mapby=LINEAGE).value,                            by=[ticker, bb_composite]));         #ndebt2ebitda = avg(group(             value(net_debt_to_ebitda(fpt='BT', fill='PREV'),                   fundamentalTicker, mapby=LINEAGE).value,             by=[ticker, bb_composite]));         #eq_cushion = dropna((#ev - #ndebt) / #ev);         #spread_per_year = dropna(#zspread / #dur);     )     get(#eq_cushion, #spread_per_year, #ndebt2ebitda)     for(members(['LG30TRUU Index'])) \"\"\"  with BQuery() as bq:     res = bq.bql(query)  df = res.combine().drop_nulls() df.head(3)  Out[\u00a0]: shape: (3, 8)ID#eq_cushionORIG_IDSTICKERBB_COMPOSITE#spread_per_yearDATE#ndebt2ebitdastrf64strstrstrf64datef64\"ABEGET:B-\"0.332338\"YJ291755 Corp\"\"ABEGET\"\"B-\"756.8570512025-12-195.402544\"ACALTD:BB\"0.785345\"BM122057 Corp\"\"ACALTD\"\"BB\"-10837.8044372025-12-191.572696\"ACKAF:B\"0.363201\"ZI967285 Corp\"\"ACKAF\"\"B\"130.2812492025-12-194.563269"},{"location":"examples/credit/equity-cushion-vs-spread/#credit-spreads-vs-equity-cushion","title":"Credit Spreads vs Equity Cushion\u00b6","text":"<p>\u00a9 2025 Marek Ozana</p> <p>This notebook uses polars-bloomberg to study how bond spreads relate to a company\u2019s equity cushion, (EV-NetDebt) / EV</p> <p>We plot each issuer as a scatter point using average z-spread per year of duration versus equity cushion and highlight the typical \u201chockey-stick\u201d pattern: spreads are fairly stable at healthy cushions, then widen rapidly when the cushion becomes thin.</p> <p>Implementation detail: in Bloomberg BQL we map each bond to its issuer fundamentals via <code>fundamentalTicker</code> (mapby=LINEAGE), then group by <code>ticker</code> and rating to aggregate bond-level spread/duration and issuer-level fundamentals into one issuer datapoint.</p>"},{"location":"examples/equity/","title":"Equity Examples","text":"<p>\u00a9 2025 Marek Ozana</p> <p>These examples show how to use <code>polars-bloomberg</code> for equity analysis</p> <ul> <li> <p> S&amp;P 500 Annual Returns</p> <p>Historgram of S&amp;P 500 annual returns.  Open</p> </li> <li> <p> S&amp;P 500 EPS Estimates Progression</p> <p>See how analysts revise S&amp;P 50 earning estimates with time.</p> <p> Open</p> </li> </ul>"},{"location":"examples/equity/spx-annual-returns/","title":"S&amp;P 500 Annual Returns Histogram","text":"Out[8]: In\u00a0[9]: Copied! <pre># Get historical S&amp;P 500 annual price returns\n\nfrom polars_bloomberg import BQuery\n\nbin_names: list = [\n    \"&lt; -50\",\n    \"-50 to -40\",\n    \"-40 to -30\",\n    \"-30 to -20\",\n    \"-20 to -10\",\n    \"-10 to 0\",\n    \"0 to 10\",\n    \"10 to 20\",\n    \"20 to 30\",\n    \"30 to 40\",\n    \"40 to 50\",\n    \"&gt; 50\",\n]\nbins = list(range(-50, 60, 10))\n\nquery = f\"\"\"\nlet(\n    #rets = dropna(pct_diff(px_last(dates=range(-100Y, 0Y), per=Y)));\n    #bins = bins(#rets, {bins}, bin_names={bin_names});\n)\nget(#rets, #bins)\nfor(['SPX Index'])\n\"\"\"\nwith BQuery() as bq:\n    df = bq.bql(query).combine()\ndf.head(3)\n</pre> # Get historical S&amp;P 500 annual price returns  from polars_bloomberg import BQuery  bin_names: list = [     \"&lt; -50\",     \"-50 to -40\",     \"-40 to -30\",     \"-30 to -20\",     \"-20 to -10\",     \"-10 to 0\",     \"0 to 10\",     \"10 to 20\",     \"20 to 30\",     \"30 to 40\",     \"40 to 50\",     \"&gt; 50\", ] bins = list(range(-50, 60, 10))  query = f\"\"\" let(     #rets = dropna(pct_diff(px_last(dates=range(-100Y, 0Y), per=Y)));     #bins = bins(#rets, {bins}, bin_names={bin_names}); ) get(#rets, #bins) for(['SPX Index']) \"\"\" with BQuery() as bq:     df = bq.bql(query).combine() df.head(3) Out[9]: shape: (3, 4)ID#retsDATE#binsstrf64datestr\"SPX Index\"37.882221928-12-31\"30 to 40\"\"SPX Index\"-11.9096511929-12-31\"-20 to -10\"\"SPX Index\"-28.4848481930-12-31\"-30 to -20\""},{"location":"examples/equity/spx-annual-returns/#sp-500-annual-returns-histogram","title":"S&amp;P 500 Annual Returns Histogram\u00b6","text":"<p>\u00a9 2025 Marek Ozana</p> <p>Histogram of S&amp;P 500 annual returns since 100 years back.</p>"},{"location":"examples/equity/spx-eps-estimates/","title":"S&amp;P 500 Earning Per Share Estimates","text":"Out[1]: In\u00a0[2]: Copied! <pre># Download data for multiple fiscal periods\nimport polars as pl\n\nfrom polars_bloomberg import BQuery\n\nwith BQuery(timeout=50000) as con:\n    res = []\n    for n in range(1, 4):\n        tbl = con.bql(f\"\"\"\n            let(#eps=headline_eps_market(\n                    fa_period_offset={n},\n                    fa_period_type=A,\n                    as_of_date=range('2009-12-31', TODAY(), frq=W)\n                    );\n            )\n            get(#eps)\n            for(['SPX Index'])\n        \"\"\").combine()\n        res.append(tbl)\ndata = pl.concat(res).drop_nulls().sort(by=\"AS_OF_DATE\")\ndata.head(3)\n</pre> # Download data for multiple fiscal periods import polars as pl  from polars_bloomberg import BQuery  with BQuery(timeout=50000) as con:     res = []     for n in range(1, 4):         tbl = con.bql(f\"\"\"             let(#eps=headline_eps_market(                     fa_period_offset={n},                     fa_period_type=A,                     as_of_date=range('2009-12-31', TODAY(), frq=W)                     );             )             get(#eps)             for(['SPX Index'])         \"\"\").combine()         res.append(tbl) data = pl.concat(res).drop_nulls().sort(by=\"AS_OF_DATE\") data.head(3) Out[2]: shape: (3, 6)ID#epsCURRENCYREVISION_DATEAS_OF_DATEPERIOD_END_DATEstrf64strdatedatedate\"SPX Index\"62.792159\"USD\"2009-12-312009-12-312009-12-31\"SPX Index\"79.130444\"USD\"2009-12-312009-12-312010-12-31\"SPX Index\"95.303385\"USD\"2009-12-312009-12-312011-12-31"},{"location":"examples/equity/spx-eps-estimates/#sp-500-earning-per-share-estimates","title":"S&amp;P 500 Earning Per Share Estimates\u00b6","text":"<p>\u00a9 2025 Marek Ozana</p> <p>Historical development of EPS estimates for S&amp;P 500. Notice how estimates are always high for 3 years forward but then adjust to reality...</p>"},{"location":"examples/macro/","title":"Macro Examples","text":"<p>\u00a9 2026 Jim Domeij &amp; Marek Ozana</p> <p>These examples show how to use <code>polars-bloomberg</code> for macro analysis, inspired by ideas from my friend Jim Domeij. Thank you, Jim, for contributing your perspective and making it possible for others to learn from your macro thinking.</p> <ul> <li> <p> Central Bank Rate Changes (G20)</p> <p>Monitor the breadth of global monetary policy by tracking monthly hikes and cuts across G20 central banks.  Open</p> </li> <li> <p> Central Bank Policy Rates</p> <p>Compare realized policy rates with Bloomberg median forecasts across major central banks.  Open</p> </li> <li> <p> Regional P/E Valuation</p> <p>Compare regional forward P/E levels versus 10-year history.  Open</p> </li> <li> <p> SPX Valuation Scenarios</p> <p>Explore S&amp;P 500 fair value under changing P/E and EPS Growth assumptions.  Open</p> </li> <li> <p> SPX Earnings Revisions Breadth</p> <p>Monitor how earnings revisions are distributed across sectors.  Open</p> </li> <li> <p> Historical FED Policy Rates vs Expectations</p> <p>Track how Fed funds rate forecasts shifted year by year versus realized policy.  Open</p> </li> </ul>"},{"location":"examples/macro/cb-policy-rates/","title":"Central Bank Policy Rates - History vs. Forecast","text":"Out[1]: In\u00a0[2]: Copied! <pre># Get historical and forecast policy rates for FED and other central banks\nfrom polars_bloomberg import BQuery\n\nquery = \"\"\"\nlet(#policy_rate = policy_rate(pr=range(2019Q1, 2027Q4), pt=Q, act_est_data=AE);)\nget(#policy_rate)\nfor(['US', 'EZ', 'GB', 'JP'])\npreferences(\n    dropCols=[\n        'TICKER',\n        'REVISION_DATE',\n        'RATE_TYPE',\n        'REPORTED_DATE',\n        'CONCEPT',\n        'ECO_SOURCE',\n        'ACT_EST_SOURCE',\n        'PERIOD',\n        'PERIOD_END_DATE',\n        'SEASONALITY'\n    ]\n)\n\"\"\"\n\nwith BQuery() as bq:\n    res = bq.bql(query)\ndf = res.combine()\ndf.head(3)\n</pre> # Get historical and forecast policy rates for FED and other central banks from polars_bloomberg import BQuery  query = \"\"\" let(#policy_rate = policy_rate(pr=range(2019Q1, 2027Q4), pt=Q, act_est_data=AE);) get(#policy_rate) for(['US', 'EZ', 'GB', 'JP']) preferences(     dropCols=[         'TICKER',         'REVISION_DATE',         'RATE_TYPE',         'REPORTED_DATE',         'CONCEPT',         'ECO_SOURCE',         'ACT_EST_SOURCE',         'PERIOD',         'PERIOD_END_DATE',         'SEASONALITY'     ] ) \"\"\"  with BQuery() as bq:     res = bq.bql(query) df = res.combine() df.head(3) Out[2]: shape: (3, 5)ID#policy_ratePERIOD_REFERENCE_DATEAS_OF_DATEACT_EST_DATAstrf64datedatestr\"US\"2.52019-03-312026-01-07\"A\"\"US\"2.52019-06-302026-01-07\"A\"\"US\"2.02019-09-302026-01-07\"A\""},{"location":"examples/macro/cb-policy-rates/#central-bank-policy-rates-history-vs-forecast","title":"Central Bank Policy Rates - History vs. Forecast\u00b6","text":"<p>\u00a9 2026 Jim Domeij</p> <p>The chart shows quarterly policy rates from 2019 onward for the US (Fed), Eurozone (ECB), UK (BoE), and Japan (BoJ), extended with Bloomberg\u2019s median economist forecasts through 2027. Solid line segments represent realized (actual) policy settings, while dashed segments show the current consensus expected path as of the data pull date. Comparing levels and slopes highlights where markets expect tightening, easing, or prolonged stability\u2014and how the projected policy divergence/convergence evolves across regions.</p>"},{"location":"examples/macro/fed-history/","title":"Historical FED Policy Rates vs Expectations","text":"Out[1]: In\u00a0[\u00a0]: Copied! <pre># Get historical and forecast policy rates for FED and other central banks\nimport polars as pl\n\nfrom polars_bloomberg import BQuery\n\nwith BQuery() as bq:\n    lst = []\n    for year in range(2014, 2026):\n        df = bq.bql(\n            f\"\"\"\n            let(#policy_rate = policy_rate(pr=range(2014Q4, 2027Q2),\n                                             pt=Q, act_est_data=AE);)\n            get(#policy_rate)\n            for(['US'])\n            with(dates='{year:d}-12-31')\n            preferences(\n                dropCols=[\n                    'TICKER',\n                    'REVISION_DATE',\n                    'RATE_TYPE',\n                    'REPORTED_DATE',\n                    'CONCEPT',\n                    'ECO_SOURCE',\n                    'ACT_EST_SOURCE',\n                    'PERIOD',\n                    'PERIOD_END_DATE',\n                    'SEASONALITY'\n                ]\n            )\n            \"\"\"\n        ).combine()\n        lst.append(df)\n\ndf_tot = pl.concat(lst)\ndf_tot.head()\n</pre> # Get historical and forecast policy rates for FED and other central banks import polars as pl  from polars_bloomberg import BQuery  with BQuery() as bq:     lst = []     for year in range(2014, 2026):         df = bq.bql(             f\"\"\"             let(#policy_rate = policy_rate(pr=range(2014Q4, 2027Q2),                                              pt=Q, act_est_data=AE);)             get(#policy_rate)             for(['US'])             with(dates='{year:d}-12-31')             preferences(                 dropCols=[                     'TICKER',                     'REVISION_DATE',                     'RATE_TYPE',                     'REPORTED_DATE',                     'CONCEPT',                     'ECO_SOURCE',                     'ACT_EST_SOURCE',                     'PERIOD',                     'PERIOD_END_DATE',                     'SEASONALITY'                 ]             )             \"\"\"         ).combine()         lst.append(df)  df_tot = pl.concat(lst) df_tot.head() Out[\u00a0]: shape: (5, 5)ID#policy_ratePERIOD_REFERENCE_DATEAS_OF_DATEACT_EST_DATAstrf64datedatestr\"US\"0.252014-12-312014-12-31\"A\"\"US\"0.252015-03-312014-12-31\"E\"\"US\"0.42015-06-302014-12-31\"E\"\"US\"0.6500012015-09-302014-12-31\"E\"\"US\"0.9500012015-12-312014-12-31\"E\""},{"location":"examples/macro/fed-history/#historical-fed-policy-rates-vs-expectations","title":"Historical FED Policy Rates vs Expectations\u00b6","text":"<p>\u00a9 2026 Jim Domeij &amp; Marek Ozana</p> <p>This chart reconstructs how expectations for the Fed funds rate evolved over time. Each line is a year-end snapshot (<code>AS_OF_DATE</code>) of Bloomberg\u2019s median economist path for future policy rates, shown alongside realized settings. Solid segments indicate historical (actual) policy rates, while dashed segments show the forecast that was in place on that snapshot date.</p>"},{"location":"examples/macro/hikes-cuts-count/","title":"Central-bank rate changes (G20)","text":"Out[1]: In\u00a0[2]: Copied! <pre>from polars_bloomberg import BQuery\n\nquery = \"\"\"\nlet(\n    #ref_date = policy_rate().period_reference_date;\n    #policy_rate_changes = diff(dropNA(policy_rate(), remove_id=True));\n    #count_cuts = sum(group(if(#policy_rate_changes &lt; 0, 1, 0), by=#ref_date));\n    #count_hikes = sum(group(if(#policy_rate_changes &gt; 0, 1, 0), by=#ref_date));\n    #net_hike_count = #count_hikes - #count_cuts;\n)\nget(#count_cuts, #count_hikes, #net_hike_count)\nfor(countries('G20'))\nwith(pr=range(2016M12, 2025M12), pt=M, act_est_data=A, fill=PREV)\npreferences(dropCols=[\"ORIG_IDS\"])\n\"\"\"\n\nwith BQuery() as bq:\n    df = bq.bql(query).combine()\ndf.head(3)\n</pre> from polars_bloomberg import BQuery  query = \"\"\" let(     #ref_date = policy_rate().period_reference_date;     #policy_rate_changes = diff(dropNA(policy_rate(), remove_id=True));     #count_cuts = sum(group(if(#policy_rate_changes &lt; 0, 1, 0), by=#ref_date));     #count_hikes = sum(group(if(#policy_rate_changes &gt; 0, 1, 0), by=#ref_date));     #net_hike_count = #count_hikes - #count_cuts; ) get(#count_cuts, #count_hikes, #net_hike_count) for(countries('G20')) with(pr=range(2016M12, 2025M12), pt=M, act_est_data=A, fill=PREV) preferences(dropCols=[\"ORIG_IDS\"]) \"\"\"  with BQuery() as bq:     df = bq.bql(query).combine() df.head(3) Out[2]: shape: (3, 5)ID#count_cuts#REF_DATE#count_hikes#net_hike_countstrf64datef64f64\"2016-12-31T00-00-00Z\"0.02016-12-310.00.0\"2017-01-31T00-00-00Z\"1.02017-01-310.0-1.0\"2017-02-28T00-00-00Z\"1.02017-02-281.00.0"},{"location":"examples/macro/hikes-cuts-count/#central-bank-rate-changes-g20","title":"Central-bank rate changes (G20)\u00b6","text":"<p>\u00a9 2026 Jim Domeij</p> <p>Each month, we count how many G20 central banks raised their policy rate (hikes) and how many lowered it (cuts), as a simple proxy for the breadth of global tightening vs easing.</p> <p>The top panel shows hikes (up) and cuts (down). The bottom panel shows the net balance on the same scale.</p> <p>Note: This is a count of central banks changing rates, not the magnitude of the rate moves.</p>"},{"location":"examples/macro/pe-valuations/","title":"Regional PE Valuation","text":"Out[1]: In\u00a0[2]: Copied! <pre># Get P/E for different regions\nfrom polars_bloomberg import BQuery\n\nquery = \"\"\"\nlet(\n    #series=headline_pe_ratio(dates=range(-10Y, 0D, frq=D));\n    #avg=avg(#series);\n    #std=std(#series);\n    #min=min(#series);\n    #max=max(#series);\n    #last=headline_pe_ratio();\n)\nfor([\n    'SPX Index',\n    'B500XM7T Index',\n    'SXXP Index',\n    'TPX Index',\n    'UKX Index',\n    'MXEF Index',\n    'SHSZ300 Index'\n])\nget(#avg, #std, #min, #max, #last)\nwith(fpt=BT, fpo=1)\npreferences(dropCols=['REVISION_DATE', 'AS_OF_DATE', 'PERIOD_END_DATE'])\n\"\"\"\n\nwith BQuery() as bq:\n    df = bq.bql(query).combine()\ndf.head()\n</pre> # Get P/E for different regions from polars_bloomberg import BQuery  query = \"\"\" let(     #series=headline_pe_ratio(dates=range(-10Y, 0D, frq=D));     #avg=avg(#series);     #std=std(#series);     #min=min(#series);     #max=max(#series);     #last=headline_pe_ratio(); ) for([     'SPX Index',     'B500XM7T Index',     'SXXP Index',     'TPX Index',     'UKX Index',     'MXEF Index',     'SHSZ300 Index' ]) get(#avg, #std, #min, #max, #last) with(fpt=BT, fpo=1) preferences(dropCols=['REVISION_DATE', 'AS_OF_DATE', 'PERIOD_END_DATE']) \"\"\"  with BQuery() as bq:     df = bq.bql(query).combine() df.head() Out[2]: shape: (5, 6)ID#avg#std#min#max#laststrf64f64f64f64f64\"SPX Index\"18.8542042.22921913.56365823.33970922.050241\"B500XM7T Index\"17.7253931.80734812.61370221.70409319.95632\"SXXP Index\"14.4643781.57935910.63840118.88942115.256618\"TPX Index\"14.7181921.77861611.11671520.4753116.522521\"UKX Index\"12.7916361.7028298.70259617.19144913.389673"},{"location":"examples/macro/pe-valuations/#regional-pe-valuation","title":"Regional PE Valuation\u00b6","text":"<p>\u00a9 2026 Jim Domeij</p> <p>This calculates 10-year P/E valuation statistics (average, standard deviation, minimum and maximum) for major equity regions. Current levels are compared to these statistics to assess the relative expansiveness vs history and other regions.</p> <p>The BQL query builds a shared 10-year date range, defines a reusable forward P/E series, and computes <code>#avg</code>, <code>#std</code>, <code>#min</code>, <code>#max</code>, plus the latest value <code>#last</code> for each index in the universe. BQL returns a Polars DataFrame with <code>ID</code> and those five fields, which are renamed for plotting.</p> <p>The chart visualizes each region\u2019s distribution using a box for average \u00b11 standard deviation, whiskers for min/max, a diamond for the average, and a triangle for the latest value.</p>"},{"location":"examples/macro/spx-earning-revisions-breadth/","title":"S&amp;P 500 Earning Revisions Breadth","text":"Out[1]: In\u00a0[2]: Copied! <pre># Get counts of comps with positive and negative earnings revisions over the past month\nfrom polars_bloomberg import BQuery\n\nquery = \"\"\"\n    let(\n        #rev = net_chg(is_eps(fpt=BT, fpo=1, ae=e, dates=range(-1M, 0d)));\n        #sector = classification_name(gics, 1);\n\n        #up   = sum(group(if(#rev &gt; 0, 1, 0), #sector));\n        #down = sum(group(if(#rev &lt; 0, 1, 0), #sector));\n    )\n    get(#up, #down)\n    for(members(\"SPX Index\"))\n    preferences(dropCols=[\"ORIG_IDS\", \"#sector\"])\n    \"\"\"\n\nwith BQuery() as bq:\n    df = bq.bql(query).combine()\ndf.head()\n</pre> # Get counts of comps with positive and negative earnings revisions over the past month from polars_bloomberg import BQuery  query = \"\"\"     let(         #rev = net_chg(is_eps(fpt=BT, fpo=1, ae=e, dates=range(-1M, 0d)));         #sector = classification_name(gics, 1);          #up   = sum(group(if(#rev &gt; 0, 1, 0), #sector));         #down = sum(group(if(#rev &lt; 0, 1, 0), #sector));     )     get(#up, #down)     for(members(\"SPX Index\"))     preferences(dropCols=[\"ORIG_IDS\", \"#sector\"])     \"\"\"  with BQuery() as bq:     df = bq.bql(query).combine() df.head() Out[2]: shape: (5, 3)ID#up#downstrf64f64\"Communication Services\"18.03.0\"Consumer Discretionary\"41.08.0\"Consumer Staples\"29.07.0\"Energy\"12.010.0\"Financials\"65.09.0"},{"location":"examples/macro/spx-earning-revisions-breadth/#sp-500-earning-revisions-breadth","title":"S&amp;P 500 Earning Revisions Breadth\u00b6","text":"<p>\u00a9 2025 Jim Domeij &amp; Marek Ozana</p> <p>This calculates, for each GICS sector within the S&amp;P 500, the number of companies with upward or downward EPS revisions over the past month. It can be used to track the breadth of change in analysts\u2019 EPS estimates by sector.</p>"},{"location":"examples/macro/spx-valuation-scenarios/","title":"S&amp;P 500 Valuation Scenarios","text":"Out[1]: In\u00a0[2]: Copied! <pre># BQL Code to fetch SPX valuation data\nimport polars as pl\n\nfrom polars_bloomberg import BQuery\n\nquery = \"\"\"\n    let(\n        #last_price = px_last();\n        #12m_trail_eps = headline_eps_market(fpt=LTM);\n        #12m_fwd_eps = headline_eps_market(fpt=BT, fpo=1);\n        #epsg_consensus = #12m_fwd_eps/#12m_trail_eps - 1;\n        #current_pe = headline_pe_ratio(fpt=BT, fpo=1);\n        #5y_avg_pe = avg(headline_pe_ratio(fpt=BT, fpo=1, fill=PREV, dates=range(-5Y, 0D, frq=W)));\n        #10y_avg_pe = avg(headline_pe_ratio(fpt=BT, fpo=1, fill=PREV, dates=range(-10Y, 0D, frq=W)));\n        #20y_avg_pe = avg(headline_pe_ratio(fpt=BT, fpo=1, fill=PREV, dates=range(-20Y, 0D, frq=W)));\n        #35y_avg_pe = avg(headline_pe_ratio(fpt=BT, fpo=1, fill=PREV, dates=range(-35Y, 0D, frq=W)));\n        #max_pe = max(headline_pe_ratio(fpt=BT, fpo=1, fill=PREV, dates=range(-35Y, 0D, frq=W)));\n    )\n    get(\n        #last_price,\n        #12m_trail_eps,\n        #12m_fwd_eps,\n        #epsg_consensus,\n        #current_pe,\n        #5y_avg_pe,\n        #10y_avg_pe,\n        #20y_avg_pe,\n        #35y_avg_pe,\n        #max_pe\n    )\n    preferences(dropCols=['CURRENCY', 'DATE', 'AS_OF_DATE', 'REVISION_DATE', 'PERIOD_END_DATE'])\n    for('SPX Index')\n\"\"\"  # noqa: E501\nwith BQuery() as bq:\n    res = bq.bql(query)\n\ndf = res.combine()\ndf\n</pre> # BQL Code to fetch SPX valuation data import polars as pl  from polars_bloomberg import BQuery  query = \"\"\"     let(         #last_price = px_last();         #12m_trail_eps = headline_eps_market(fpt=LTM);         #12m_fwd_eps = headline_eps_market(fpt=BT, fpo=1);         #epsg_consensus = #12m_fwd_eps/#12m_trail_eps - 1;         #current_pe = headline_pe_ratio(fpt=BT, fpo=1);         #5y_avg_pe = avg(headline_pe_ratio(fpt=BT, fpo=1, fill=PREV, dates=range(-5Y, 0D, frq=W)));         #10y_avg_pe = avg(headline_pe_ratio(fpt=BT, fpo=1, fill=PREV, dates=range(-10Y, 0D, frq=W)));         #20y_avg_pe = avg(headline_pe_ratio(fpt=BT, fpo=1, fill=PREV, dates=range(-20Y, 0D, frq=W)));         #35y_avg_pe = avg(headline_pe_ratio(fpt=BT, fpo=1, fill=PREV, dates=range(-35Y, 0D, frq=W)));         #max_pe = max(headline_pe_ratio(fpt=BT, fpo=1, fill=PREV, dates=range(-35Y, 0D, frq=W)));     )     get(         #last_price,         #12m_trail_eps,         #12m_fwd_eps,         #epsg_consensus,         #current_pe,         #5y_avg_pe,         #10y_avg_pe,         #20y_avg_pe,         #35y_avg_pe,         #max_pe     )     preferences(dropCols=['CURRENCY', 'DATE', 'AS_OF_DATE', 'REVISION_DATE', 'PERIOD_END_DATE'])     for('SPX Index') \"\"\"  # noqa: E501 with BQuery() as bq:     res = bq.bql(query)  df = res.combine() df Out[2]: shape: (1, 11)ID#last_price#12m_trail_eps#12m_fwd_eps#epsg_consensus#current_pe#5y_avg_pe#10y_avg_pe#20y_avg_pe#35y_avg_pe#max_pestrf64f64f64f64f64f64f64f64f64f64\"SPX Index\"6753.61269.207986307.4173240.14193222.12061420.04152518.82558816.33163116.77189225.532804"},{"location":"examples/macro/spx-valuation-scenarios/#sp-500-valuation-scenarios","title":"S&amp;P 500 Valuation Scenarios\u00b6","text":"<p>\u00a9 2025 Jim Domeij &amp; Marek Ozana</p> <p>This chart shows potential S&amp;P 500 price levels and returns for the next 12 months. It uses a scenario matrix driven by two factors: Forward P/E ratios (vertical axis, from historical averages) and Forward EPS growth (horizontal axis, centered on consensus). Each cell displays the resulting index price and percentage return from the current price. This helps investors visualize risk and potential upside under different market conditions.</p>"},{"location":"usage/bdh/","title":"BDH","text":"<p>Use Case: Retrieve historical data over a date range, such as daily closing prices or volumes. <pre><code>with BQuery() as bq:\n    df = bq.bdh(\n        [\"TLT US Equity\"],\n        [\"PX_LAST\"],\n        start_date=date(2019, 1, 1),\n        end_date=date(2019, 1, 7),\n    )\n    print(df)\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 security      \u2506 date       \u2506 PX_LAST \u2502\n\u2502 ---           \u2506 ---        \u2506 ---     \u2502\n\u2502 str           \u2506 date       \u2506 f64     \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 TLT US Equity \u2506 2019-01-02 \u2506 122.15  \u2502\n\u2502 TLT US Equity \u2506 2019-01-03 \u2506 123.54  \u2502\n\u2502 TLT US Equity \u2506 2019-01-04 \u2506 122.11  \u2502\n\u2502 TLT US Equity \u2506 2019-01-07 \u2506 121.75  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"usage/bdh/#bdh-with-multiple-securities-fields","title":"BDH with multiple securities / fields","text":"<pre><code>with BQuery() as bq:\n    df = bq.bdh(\n        securities=[\"SPY US Equity\", \"TLT US Equity\"],\n        fields=[\"PX_LAST\", \"VOLUME\"],\n        start_date=date(2019, 1, 1),\n        end_date=date(2019, 1, 10),\n        options={\"adjustmentSplit\": True},\n    )\n    print(df)\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 security      \u2506 date       \u2506 PX_LAST \u2506 VOLUME       \u2502\n\u2502 ---           \u2506 ---        \u2506 ---     \u2506 ---          \u2502\n\u2502 str           \u2506 date       \u2506 f64     \u2506 f64          \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 SPY US Equity \u2506 2019-01-02 \u2506 250.18  \u2506 1.26925199e8 \u2502\n\u2502 SPY US Equity \u2506 2019-01-03 \u2506 244.21  \u2506 1.44140692e8 \u2502\n\u2502 SPY US Equity \u2506 2019-01-04 \u2506 252.39  \u2506 1.42628834e8 \u2502\n\u2502 SPY US Equity \u2506 2019-01-07 \u2506 254.38  \u2506 1.031391e8   \u2502\n\u2502 SPY US Equity \u2506 2019-01-08 \u2506 256.77  \u2506 1.02512587e8 \u2502\n\u2502 \u2026             \u2506 \u2026          \u2506 \u2026       \u2506 \u2026            \u2502\n\u2502 TLT US Equity \u2506 2019-01-04 \u2506 122.11  \u2506 1.2970226e7  \u2502\n\u2502 TLT US Equity \u2506 2019-01-07 \u2506 121.75  \u2506 8.498104e6   \u2502\n\u2502 TLT US Equity \u2506 2019-01-08 \u2506 121.43  \u2506 7.737103e6   \u2502\n\u2502 TLT US Equity \u2506 2019-01-09 \u2506 121.24  \u2506 9.349245e6   \u2502\n\u2502 TLT US Equity \u2506 2019-01-10 \u2506 120.46  \u2506 8.22286e6    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"usage/bdh/#bdh-with-options-periodicityselection-monthly","title":"BDH with options - periodicitySelection: Monthly","text":"<pre><code>with BQuery() as bq:\n    df = bq.bdh(['AAPL US Equity'], \n                ['PX_LAST'], \n                start_date=date(2019, 1, 1), \n                end_date=date(2019, 3, 29),\n                options={\"periodicitySelection\": \"MONTHLY\"})\n    print(df)\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 security       \u2506 date       \u2506 PX_LAST \u2502\n\u2502 ---            \u2506 ---        \u2506 ---     \u2502\n\u2502 str            \u2506 date       \u2506 f64     \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 AAPL US Equity \u2506 2019-01-31 \u2506 41.61   \u2502\n\u2502 AAPL US Equity \u2506 2019-02-28 \u2506 43.288  \u2502\n\u2502 AAPL US Equity \u2506 2019-03-29 \u2506 47.488  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"usage/bdib/","title":"BDIB \u2013 Bloomberg Data Intraday Bar","text":"<p><code>bdib()</code> fetches pre-aggregated intraday bars directly from Bloomberg, so you can work with 1- to 1440-minute candles without managing tick-level aggregation yourself. Each bar is timestamped in UTC and returned as a Polars DataFrame.</p>"},{"location":"usage/bdib/#when-to-use-bdib","title":"When to use BDIB","text":"<ul> <li>You need intraday OHLCV bars for a single security over a specific time window.</li> <li>You want Bloomberg to enforce consistent interval lengths (e.g., 5-, 15-, 60-minute bars).</li> </ul>"},{"location":"usage/bdib/#example","title":"Example","text":"<pre><code>from datetime import datetime\nfrom polars_bloomberg import BQuery\n\nwith BQuery() as bq:\n    df = bq.bdib(\n        \"OMX Index\",\n        event_type=\"TRADE\",   # TRADE, BID, ASK, BEST_BID, BEST_ASK\n        interval=60,          # minutes (1-1440)\n        start_datetime=datetime(2025, 11, 5),\n        end_datetime=datetime(2025, 11, 5, 12),\n    )\n    print(df)\n</code></pre> <p>Sample output:</p> <pre><code>shape: (4, 9)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 security  \u2506 time         \u2506 open     \u2506 high     \u2506 \u2026 \u2506 close    \u2506 volume \u2506 numEvents \u2506 value \u2502\n\u2502 ---       \u2506 ---          \u2506 ---      \u2506 ---      \u2506   \u2506 ---      \u2506 ---    \u2506 ---       \u2506 ---   \u2502\n\u2502 str       \u2506 datetime[\u03bcs] \u2506 f64      \u2506 f64      \u2506   \u2506 f64      \u2506 i64    \u2506 i64       \u2506 f64   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 OMX Index \u2506 2025-11-05   \u2506 2726.603 \u2506 2742.014 \u2506 \u2026 \u2506 2739.321 \u2506 0      \u2506 3591      \u2506 0.0   \u2502\n\u2502           \u2506 08:00:00     \u2506          \u2506          \u2506   \u2506          \u2506        \u2506           \u2506       \u2502\n\u2502 OMX Index \u2506 2025-11-05   \u2506 2739.466 \u2506 2739.706 \u2506 \u2026 \u2506 2733.836 \u2506 0      \u2506 3600      \u2506 0.0   \u2502\n\u2502           \u2506 09:00:00     \u2506          \u2506          \u2506   \u2506          \u2506        \u2506           \u2506       \u2502\n\u2502 OMX Index \u2506 2025-11-05   \u2506 2733.747 \u2506 2734.827 \u2506 \u2026 \u2506 2731.724 \u2506 0      \u2506 3600      \u2506 0.0   \u2502\n\u2502           \u2506 10:00:00     \u2506          \u2506          \u2506   \u2506          \u2506        \u2506           \u2506       \u2502\n\u2502 OMX Index \u2506 2025-11-05   \u2506 2731.721 \u2506 2742.015 \u2506 \u2026 \u2506 2741.185 \u2506 0      \u2506 3600      \u2506 0.0   \u2502\n\u2502           \u2506 11:00:00     \u2506          \u2506          \u2506   \u2506          \u2506        \u2506           \u2506       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"usage/bdib/#notes","title":"Notes","text":"<ul> <li><code>start_datetime</code> and <code>end_datetime</code> can be naive or timezone-aware. Naive values   are treated as UTC; aware values are converted to UTC before the request is sent.</li> <li>Supported <code>event_type</code> values: <code>TRADE</code>, <code>BID</code>, <code>ASK</code>, <code>BEST_BID</code>, <code>BEST_ASK</code>.</li> <li>Bloomberg enforces the interval range (1-1440 minutes). Requests outside that   range raise a schema error.</li> <li>Optional <code>overrides</code> and <code>options</code> parameters work the same way as in <code>bdp()</code> and   <code>bdh()</code></li> </ul>"},{"location":"usage/bdp/","title":"BDP","text":"<p>Use Case: Fetch single-value data points (like last price, currency, or descriptive fields).</p> <pre><code>with BQuery() as bq:\n    df = bq.bdp([\"AAPL US Equity\", \"SEBA SS Equity\"], [\"PX_LAST\", \"CRNCY\"])\n    print(df)\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 security       \u2506 PX_LAST \u2506 CRNCY \u2502\n\u2502 ---            \u2506 ---     \u2506 ---   \u2502\n\u2502 str            \u2506 f64     \u2506 str   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 AAPL US Equity \u2506 248.13  \u2506 USD   \u2502\n\u2502 SEBA SS Equity \u2506 155.2   \u2506 SEK   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"usage/bdp/#bdp-with-different-column-types","title":"BDP with different column types","text":"<p><code>polars-bloomberg</code> correctly infers column type as shown in this example:</p> <pre><code>with BQuery() as bq:\n    df = bq.bdp([\"XS2930103580 Corp\", \"USX60003AC87 Corp\"],\n                [\"SECURITY_DES\", \"YAS_ZSPREAD\", \"CRNCY\", \"NXT_CALL_DT\"])\n    print(df)\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 security          \u2506 SECURITY_DES   \u2506 YAS_ZSPREAD \u2506 CRNCY \u2506 NXT_CALL_DT \u2502\n\u2502 ---               \u2506 ---            \u2506 ---         \u2506 ---   \u2506 ---         \u2502\n\u2502 str               \u2506 str            \u2506 f64         \u2506 str   \u2506 date        \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 XS2930103580 Corp \u2506 SEB 6 3/4 PERP \u2506 304.676112  \u2506 USD   \u2506 2031-11-04  \u2502\n\u2502 USX60003AC87 Corp \u2506 NDAFH 6.3 PERP \u2506 292.477506  \u2506 USD   \u2506 2031-09-25  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"usage/bdp/#bdp-with-overrides","title":"BDP with overrides","text":"<p>User can submit list of tuples with overrides <pre><code>with BQuery() as bq:\n    df = bq.bdp(\n        [\"IBM US Equity\"],\n        [\"PX_LAST\", \"CRNCY_ADJ_PX_LAST\"],\n        overrides=[(\"EQY_FUND_CRNCY\", \"SEK\")],\n    )\n    print(df)\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 security      \u2506 PX_LAST \u2506 CRNCY_ADJ_PX_LAST \u2502\n\u2502 ---           \u2506 ---     \u2506 ---               \u2502\n\u2502 str           \u2506 f64     \u2506 f64               \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 IBM US Equity \u2506 230.82  \u2506 2535.174          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"usage/bdp/#bdp-with-date-overrides","title":"BDP with date overrides","text":"<p>Overrides for dates has to be in format YYYYMMDD <pre><code>with BQuery() as bq:\n    df = bq.bdp([\"USX60003AC87 Corp\"], [\"SETTLE_DT\"],\n                overrides=[(\"USER_LOCAL_TRADE_DATE\", \"20241014\")])\n    print(df)\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 security          \u2506 SETTLE_DT  \u2502\n\u2502 ---               \u2506 ---        \u2502\n\u2502 str               \u2506 date       \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 USX60003AC87 Corp \u2506 2024-10-15 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> <pre><code>with BQuery() as bq:\n    df = bq.bdp(['USDSEK Curncy', 'SEKCZK Curncy'], \n                ['SETTLE_DT', 'PX_LAST'], \n                overrides=[('REFERENCE_DATE', '20200715')]\n               )\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 security      \u2506 SETTLE_DT  \u2506 PX_LAST \u2502\n\u2502 ---           \u2506 ---        \u2506 ---     \u2502\n\u2502 str           \u2506 date       \u2506 f64     \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 USDSEK Curncy \u2506 2020-07-17 \u2506 10.9778 \u2502\n\u2502 SEKCZK Curncy \u2506 2020-07-17 \u2506 2.1698  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"usage/bql/","title":"BQL","text":"<p>Use Case: Run more advanced queries to screen securities, calculate analytics (like moving averages), or pull fundamental data with complex conditions.</p> <p>Returns: The <code>bql()</code> method returns a <code>BqlResult</code> object, which:</p> <ul> <li>Acts like a list of Polars DataFrames (one for each item in BQL <code>get</code> statement).</li> <li>Provides a <code>.combine()</code> method to merge DataFrames on common columns.</li> </ul>"},{"location":"usage/bql/#basic-example","title":"Basic Example","text":"<p><pre><code># Fetch the last price of IBM stock\nwith BQuery() as bq:\n    results = bq.bql(\"get(px_last) for(['IBM US Equity'])\")\n    print(results[0])  # Access the first DataFrame\n</code></pre> Output: <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 ID            \u2506 px_last \u2506 DATE       \u2506 CURRENCY \u2502\n\u2502 ---           \u2506 ---     \u2506 ---        \u2506 ---      \u2502\n\u2502 str           \u2506 f64     \u2506 date       \u2506 str      \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 IBM US Equity \u2506 230.82  \u2506 2024-12-14 \u2506 USD      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"usage/bql/#multiple-securities","title":"Multiple Securities","text":"<p><pre><code># Fetch the last price for IBM and SEB\nwith BQuery() as bq:\n    results = bq.bql(\"get(px_last) for(['IBM US Equity', 'SEBA SS Equity'])\")\n    print(results[0])\n</code></pre> Output: <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 ID             \u2506 px_last \u2506 DATE       \u2506 CURRENCY \u2502\n\u2502 ---            \u2506 ---     \u2506 ---        \u2506 ---      \u2502\n\u2502 str            \u2506 f64     \u2506 date       \u2506 str      \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 IBM US Equity  \u2506 230.82  \u2506 2024-12-14 \u2506 USD      \u2502\n\u2502 SEBA SS Equity \u2506 155.2   \u2506 2024-12-14 \u2506 SEK      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"usage/bql/#multiple-items-combine","title":"Multiple Items - combine()","text":"<p>When querying for multiple items, <code>bql()</code> returns <code>BqlResult</code> object which is actually just a list of polars dataframes with extra method <code>combine()</code> <pre><code># Fetch name and last price of IBM (two items)\nwith BQuery() as bq:\n    results = bq.bql(\"get(name, px_last) for(['IBM US Equity'])\")\n</code></pre> Output: <pre><code>&gt;&gt;&gt; print(len(results))  # 2 DataFrames\nn=2\n\n&gt;&gt;&gt; print(results[0])    # First DataFrame: 'name'\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 ID            \u2506 name                           \u2502\n\u2502 ---           \u2506 ---                            \u2502\n\u2502 str           \u2506 str                            \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 IBM US Equity \u2506 International Business Machine \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n&gt;&gt;&gt; print(results[1])    # Second DataFrame: 'px_last'\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 ID            \u2506 px_last \u2506 DATE       \u2506 CURRENCY \u2502\n\u2502 ---           \u2506 ---     \u2506 ---        \u2506 ---      \u2502\n\u2502 str           \u2506 f64     \u2506 date       \u2506 str      \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 IBM US Equity \u2506 230.82  \u2506 2024-12-14 \u2506 USD      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> <p>We can use <code>combine()</code> method to join the results into single dataframe: <pre><code>&gt;&gt;&gt; combined_df = results.combine()\n&gt;&gt;&gt; print(combined_df)\n</code></pre> Output: <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 ID            \u2506 name                           \u2506 px_last \u2506 DATE       \u2506 CURRENCY \u2502\n\u2502 ---           \u2506 ---                            \u2506 ---     \u2506 ---        \u2506 ---      \u2502\n\u2502 str           \u2506 str                            \u2506 f64     \u2506 date       \u2506 str      \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 IBM US Equity \u2506 International Business Machine \u2506 230.82  \u2506 2024-12-14 \u2506 USD      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"usage/bql/#screening","title":"Screening","text":"<p>Example of using saved SRCH search and filtering on ticker: Find list of SEB and Handelsbanken's AT1 bonds and print their names, duration and Z-Spread. The result of the query is list of 3 polars dataframes and can be conveniently combined using <code>combine()</code> method. <pre><code>query=\"\"\"\n    let(#dur=duration(duration_type=MODIFIED); \n        #zsprd=spread(spread_type=Z);) \n    get(name(), #dur, #zsprd) \n    for(filter(screenresults(type=SRCH, screen_name='@COCO'), \n            ticker in ['SEB', 'SHBASS']))\n\"\"\"\n\nwith BQuery() as bq:\n    results = bq.bql(query)\n    combined_df = results.combine()\n    print(combined_df)\n</code></pre> Output: <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 ID            \u2506 name()          \u2506 #dur \u2506 DATE       \u2506 #zsprd \u2502\n\u2502 ---           \u2506 ---             \u2506 ---  \u2506 ---        \u2506 ---    \u2502\n\u2502 str           \u2506 str             \u2506 f64  \u2506 date       \u2506 f64    \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 BW924993 Corp \u2506 SEB 6 \u215e PERP    \u2506 2.23 \u2506 2024-12-16 \u2506 212.0  \u2502\n\u2502 YV402592 Corp \u2506 SEB Float PERP  \u2506 0.21 \u2506 2024-12-16 \u2506 233.0  \u2502\n\u2502 ZQ349286 Corp \u2506 SEB 5 \u215b PERP    \u2506 0.39 \u2506 2024-12-16 \u2506 186.0  \u2502\n\u2502 ZO703315 Corp \u2506 SHBASS 4 \u215c PERP \u2506 1.95 \u2506 2024-12-16 \u2506 213.0  \u2502\n\u2502 ZO703956 Corp \u2506 SHBASS 4 \u00be PERP \u2506 4.94 \u2506 2024-12-16 \u2506 256.0  \u2502\n\u2502 YU819930 Corp \u2506 SEB 6 \u00be PERP    \u2506 5.37 \u2506 2024-12-16 \u2506 309.0  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"usage/bql/#aggregation","title":"Aggregation","text":"<p>Average PE per Index Sector</p> <p>This example shows aggregation (average) per group (sector) for members of an index. The resulting list has only one element since there is only one data-item in <code>get</code> <pre><code>query = \"\"\"\n    let(#avg_pe=avg(group(pe_ratio(), gics_sector_name()));)\n    get(#avg_pe)\n    for(members('OMX Index'))\n\"\"\"\nwith BQuery() as bq:\n    results = bq.bql(query)\n    print(results[0].head(5))\n</code></pre> Output: <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 ID           \u2506 #avg_pe   \u2506 REVISION_DAT \u2506 AS_OF_DATE \u2506 PERIOD_END_D \u2506 ORIG_IDS     \u2506 GICS_SECTOR \u2502\n\u2502 ---          \u2506 ---       \u2506 E            \u2506 ---        \u2506 ATE          \u2506 ---          \u2506 _NAME()     \u2502\n\u2502 str          \u2506 f64       \u2506 ---          \u2506 date       \u2506 ---          \u2506 str          \u2506 ---         \u2502\n\u2502              \u2506           \u2506 date         \u2506            \u2506 date         \u2506              \u2506 str         \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Communicatio \u2506 19.561754 \u2506 2024-10-24   \u2506 2024-12-14 \u2506 2024-09-30   \u2506 null         \u2506 Communicati \u2502\n\u2502 n Services   \u2506           \u2506              \u2506            \u2506              \u2506              \u2506 on Services \u2502\n\u2502 Consumer Dis \u2506 19.117295 \u2506 2024-10-24   \u2506 2024-12-14 \u2506 2024-09-30   \u2506 null         \u2506 Consumer    \u2502\n\u2502 cretionary   \u2506           \u2506              \u2506            \u2506              \u2506              \u2506 Discretiona \u2502\n\u2502              \u2506           \u2506              \u2506            \u2506              \u2506              \u2506 ry          \u2502\n\u2502 Consumer     \u2506 15.984743 \u2506 2024-10-24   \u2506 2024-12-14 \u2506 2024-09-30   \u2506 ESSITYB SS   \u2506 Consumer    \u2502\n\u2502 Staples      \u2506           \u2506              \u2506            \u2506              \u2506 Equity       \u2506 Staples     \u2502\n\u2502 Financials   \u2506 6.815895  \u2506 2024-10-24   \u2506 2024-12-14 \u2506 2024-09-30   \u2506 null         \u2506 Financials  \u2502\n\u2502 Health Care  \u2506 22.00628  \u2506 2024-11-12   \u2506 2024-12-14 \u2506 2024-09-30   \u2506 null         \u2506 Health Care \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> <p>HY Maturity Wall</p> <p>And another example on the same topic. Calculate amount outstanding bonds in HY index per maturity year <pre><code>query = \"\"\"\nlet(#mv=sum(group(amt_outstanding(currency=USD),\n                  by=[year(maturity()), industry_sector()]));)\nget(#mv)\nfor(members('LF98TRUU Index'))\n\"\"\"\nwith BQuery() as bq:\n    results = bq.bql(query)\ndf = results.combine().rename(\n    {\"YEAR(MATURITY())\": \"maturity\", \"INDUSTRY_SECTOR()\": \"sector\", \"#mv\": \"mv\"}\n)\n\nprint(df.pivot(index=\"maturity\", on=\"sector\", values=\"mv\").head())\n</code></pre> Output: <pre><code>shape: (5, 11)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 maturity \u2506 Basic     \u2506 Consumer, \u2506 Energy    \u2506 \u2026 \u2506 Financial \u2506 Technolog \u2506 Utilities \u2506 Diversifi \u2502\n\u2502 ---      \u2506 Materials \u2506 Non-cycli \u2506 ---       \u2506   \u2506 ---       \u2506 y         \u2506 ---       \u2506 ed        \u2502\n\u2502 i64      \u2506 ---       \u2506 cal       \u2506 f64       \u2506   \u2506 f64       \u2506 ---       \u2506 f64       \u2506 ---       \u2502\n\u2502          \u2506 f64       \u2506 ---       \u2506           \u2506   \u2506           \u2506 f64       \u2506           \u2506 f64       \u2502\n\u2502          \u2506           \u2506 f64       \u2506           \u2506   \u2506           \u2506           \u2506           \u2506           \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2025     \u2506 1.5e8     \u2506 5.34916e8 \u2506 5e8       \u2506 \u2026 \u2506 null      \u2506 null      \u2506 null      \u2506 null      \u2502\n\u2502 2026     \u2506 4.4013e9  \u2506 9.3293e9  \u2506 8.2931e9  \u2506 \u2026 \u2506 1.3524e10 \u2506 4.0608e9  \u2506 2.5202e9  \u2506 null      \u2502\n\u2502 2027     \u2506 8.3921e9  \u2506 2.3409e10 \u2506 1.2427e10 \u2506 \u2026 \u2506 1.9430e10 \u2506 4.3367e9  \u2506 3.6620e9  \u2506 null      \u2502\n\u2502 2028     \u2506 1.4701e10 \u2506 3.7457e10 \u2506 2.2442e10 \u2506 \u2026 \u2506 2.3341e10 \u2506 9.9143e9  \u2506 7.6388e9  \u2506 5e8       \u2502\n\u2502 2029     \u2506 1.6512e10 \u2506 5.7381e10 \u2506 3.9286e10 \u2506 \u2026 \u2506 4.2337e10 \u2506 2.2660e10 \u2506 5.8558e9  \u2506 null      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"usage/bql/#axes","title":"Axes","text":"<p>Get current axes of all Swedish USD AT1 bonds <pre><code># Get current axes for Swedish AT1 bonds in USD\nquery=\"\"\"\n    let(#ax=axes();)\n    get(security_des, #ax)\n    for(filter(bondsuniv(ACTIVE),\n        crncy()=='USD' and\n        basel_iii_designation() == 'Additional Tier 1' and\n        country_iso() == 'SE'))\n\"\"\"\n\nwith BQuery() as bq:\n    results = bq.bql(query)\n    print(results.combine())\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 ID            \u2506 security_des    \u2506 #ax \u2506 ASK_DEPTH \u2506 BID_DEPTH \u2506 ASK_TOTAL_SIZE \u2506 BID_TOTAL_SIZE \u2502\n\u2502 ---           \u2506 ---             \u2506 --- \u2506 ---       \u2506 ---       \u2506 ---            \u2506 ---            \u2502\n\u2502 str           \u2506 str             \u2506 str \u2506 i64       \u2506 i64       \u2506 f64            \u2506 f64            \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 YU819930 Corp \u2506 SEB 6 \u00be PERP    \u2506 Y   \u2506 2         \u2506 null      \u2506 5.6e6          \u2506 null           \u2502\n\u2502 ZO703315 Corp \u2506 SHBASS 4 \u215c PERP \u2506 Y   \u2506 1         \u2506 2         \u2506 5e6            \u2506 6e6            \u2502\n\u2502 BR069680 Corp \u2506 SWEDA 4 PERP    \u2506 Y   \u2506 null      \u2506 1         \u2506 null           \u2506 3e6            \u2502\n\u2502 ZL122341 Corp \u2506 SWEDA 7 \u215d PERP  \u2506 Y   \u2506 null      \u2506 6         \u2506 null           \u2506 2.04e7         \u2502\n\u2502 ZQ349286 Corp \u2506 SEB 5 \u215b PERP    \u2506 Y   \u2506 2         \u2506 4         \u2506 5.5e6          \u2506 3e7            \u2502\n\u2502 ZF859199 Corp \u2506 SWEDA 7 \u00be PERP  \u2506 Y   \u2506 1         \u2506 1         \u2506 2e6            \u2506 2e6            \u2502\n\u2502 ZO703956 Corp \u2506 SHBASS 4 \u00be PERP \u2506 Y   \u2506 1         \u2506 3         \u2506 1.2e6          \u2506 1.1e7          \u2502\n\u2502 BW924993 Corp \u2506 SEB 6 \u215e PERP    \u2506 Y   \u2506 1         \u2506 3         \u2506 5e6            \u2506 1.1e7          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"usage/bql/#segments","title":"Segments","text":"<p>The following example shows handling of two data-items with different length. The first dataframe  describes the segments (and has length 5 in this case), while the second dataframe contains time series. One can join the dataframes on common columns and pivot the segments into columns as shown below: <pre><code># revenue per segment\nquery = \"\"\"\n    let(#segment=segment_name();\n        #revenue=sales_Rev_turn(fpt=q, fpr=range(2023Q3, 2024Q3));\n        )\n    get(#segment, #revenue)\n    for(segments('GTN US Equity',type=reported,hierarchy=PRODUCT, level=1))\n\"\"\"\nwith BQuery() as bq:\n    results = bq.bql(query)\n    df = results.combine().pivot(\n        index=\"PERIOD_END_DATE\", on=\"#segment\", values=\"#revenue\"\n    )\n    print(df)\n</code></pre> Output: <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 PERIOD_END_DATE \u2506 Broadcasting \u2506 Production Companies \u2506 Other  \u2506 Adjustment \u2502\n\u2502 ---             \u2506 ---          \u2506 ---                  \u2506 ---    \u2506 ---        \u2502\n\u2502 date            \u2506 f64          \u2506 f64                  \u2506 f64    \u2506 f64        \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2023-09-30      \u2506 7.83e8       \u2506 2e7                  \u2506 1.6e7  \u2506 null       \u2502\n\u2502 2023-12-31      \u2506 8.13e8       \u2506 3.2e7                \u2506 1.9e7  \u2506 null       \u2502\n\u2502 2024-03-31      \u2506 7.8e8        \u2506 2.4e7                \u2506 1.9e7  \u2506 null       \u2502\n\u2502 2024-06-30      \u2506 8.08e8       \u2506 1.8e7                \u2506 0.0    \u2506 null       \u2502\n\u2502 2024-09-30      \u2506 9.24e8       \u2506 2.6e7                \u2506 1.7e7  \u2506 null       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"usage/bql/#time-series","title":"Time Series","text":"<p>This is example of a single-item query returning total return for all GTN bonds in a long dataframe. We can easily pivot it into wide format, as in the example below <pre><code># Total Return of GTN Bonds\nquery = \"\"\"\nlet(#rng = range(-1M, 0D);\n    #rets = return_series(calc_interval=#rng,per=W);)\nget(#rets)\nfor(filter(bonds('GTN US Equity'), series() == '144A'))\n\"\"\"\n\nwith BQuery() as bq:\n    results = bq.bql(query)\n    df = results[0].pivot(on=\"ID\", index=\"DATE\", values=\"#rets\")\n    print(df)\n</code></pre> Output: <pre><code>shape: (6, 6)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 DATE       \u2506 YX231113 Corp \u2506 BS116983 Corp \u2506 AV438089 Corp \u2506 ZO860846 Corp \u2506 LW375188 Corp \u2502\n\u2502 ---        \u2506 ---           \u2506 ---           \u2506 ---           \u2506 ---           \u2506 ---           \u2502\n\u2502 date       \u2506 f64           \u2506 f64           \u2506 f64           \u2506 f64           \u2506 f64           \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2024-11-17 \u2506 null          \u2506 null          \u2506 null          \u2506 null          \u2506 null          \u2502\n\u2502 2024-11-24 \u2506 0.001653      \u2506 0.051179      \u2506 0.020363      \u2506 0.001371      \u2506 -0.002939     \u2502\n\u2502 2024-12-01 \u2506 0.002837      \u2506 0.010405      \u2506 -0.001466     \u2506 0.007275      \u2506 0.000581      \u2502\n\u2502 2024-12-08 \u2506 -0.000041     \u2506 0.016145      \u2506 0.000766      \u2506 0.024984      \u2506 0.000936      \u2502\n\u2502 2024-12-15 \u2506 0.001495      \u2506 -0.047        \u2506 -0.000233     \u2506 -0.043509     \u2506 0.002241      \u2502\n\u2502 2024-12-17 \u2506 0.00008       \u2506 -0.000004     \u2506 -0.0035       \u2506 -0.007937     \u2506 0.000064      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"usage/bql/#technical-analysis","title":"Technical Analysis","text":"<p><pre><code>with BQuery() as bq:\n    results = bq.bql(\n        \"\"\"\n        let(#ema20=emavg(period=20);\n            #ema200=emavg(period=200);\n            #rsi=rsi(close=px_last());)\n        get(name(), #ema20, #ema200, #rsi)\n        for(filter(members('OMX Index'),\n                    and(#ema20 &gt; #ema200, #rsi &gt; 53)))\n        with(fill=PREV)\n        \"\"\"\n    )\n    print(results.combine())\n</code></pre> Output: <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 ID              \u2506 name()           \u2506 #ema20     \u2506 DATE       \u2506 CURRENCY \u2506 #ema200    \u2506 #rsi      \u2502\n\u2502 ---             \u2506 ---              \u2506 ---        \u2506 ---        \u2506 ---      \u2506 ---        \u2506 ---       \u2502\n\u2502 str             \u2506 str              \u2506 f64        \u2506 date       \u2506 str      \u2506 f64        \u2506 f64       \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 ERICB SS Equity \u2506 Telefonaktiebola \u2506 90.152604  \u2506 2024-12-16 \u2506 SEK      \u2506 75.072151  \u2506 56.010028 \u2502\n\u2502                 \u2506 get LM Ericsso   \u2506            \u2506            \u2506          \u2506            \u2506           \u2502\n\u2502 ABB SS Equity   \u2506 ABB Ltd          \u2506 630.622469 \u2506 2024-12-16 \u2506 SEK      \u2506 566.571183 \u2506 53.763102 \u2502\n\u2502 SEBA SS Equity  \u2506 Skandinaviska    \u2506 153.80595  \u2506 2024-12-16 \u2506 SEK      \u2506 150.742394 \u2506 56.460733 \u2502\n\u2502                 \u2506 Enskilda Banken  \u2506            \u2506            \u2506          \u2506            \u2506           \u2502\n\u2502 ASSAB SS Equity \u2506 Assa Abloy AB    \u2506 339.017591 \u2506 2024-12-16 \u2506 SEK      \u2506 317.057573 \u2506 53.351619 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"usage/bsrch/","title":"BSRCH","text":"<p>Use case: Excel-style searches (SRCH/BI domains). Good for running saved SRCH screens or Bloomberg BI templates.</p> <p>Key points: - Pass <code>overrides</code> as a dict; values are stringified. Common keys: <code>LIMIT</code> to raise the row cap (default ~5k), custom keys like <code>BIKEY</code> for BI templates, or domain-specific parameters.</p>"},{"location":"usage/bsrch/#example-two-coco-bonds-limit2","title":"Example: two COCO bonds (LIMIT=2)","text":"<pre><code>from polars_bloomberg import BQuery\n\nwith BQuery() as bq:\n    df = bq.bsrch(\"FI:SRCHEX.@COCO\", overrides={\"LIMIT\": 2})\n    print(df)\n\n# shape: (2, 1)\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 id           \u2502\n# \u2502 ---          \u2502\n# \u2502 str          \u2502\n# \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n# \u2502 DA785784 Corp\u2502\n# \u2502 DA773901 Corp\u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"usage/bsrch/#example-bi-template-bitpd-with-bikey-limit","title":"Example: BI template (BI:TPD) with BIKEY + LIMIT","text":"<pre><code>from polars_bloomberg import BQuery\n\nwith BQuery() as bq:\n    df = bq.bsrch(\n        \"BI:TPD\",\n        overrides={\n            \"BIKEY\": \"DKOCVGXJVU8II8M90W8JSQEKR\",\n            \"LIMIT\": 20000,  # avoid ReachMax\n        },\n    )\n    print(df.head())\n\n# Example output (truncated):\n# shape: (16, 6)\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 Main_Cat \u2506 Bclass3_ \u2506 Category\u2506 06/30/20 \u2506 03/31/20 \u2506 12/31/20\u2502\n# \u2502 ...      \u2506 ...      \u2506 ...     \u2506 25       \u2506 25       \u2506 24      \u2502\n# \u2502 str      \u2506 str      \u2506 str     \u2506 f64      \u2506 f64      \u2506 f64     \u2502\n# \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n# \u2502 Leverage \u2506 Non-Fin\u2026 \u2506 B       \u2506 3.956051 \u2506 4.118212 \u2506 4.269732\u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"}]}